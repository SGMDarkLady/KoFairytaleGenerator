{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba260b6",
   "metadata": {},
   "source": [
    "# Debiasing Word Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c0802",
   "metadata": {},
   "source": [
    "## 0. make word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7b0687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이육샛별\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim import models\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5269b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e408ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1314 entries, 0 to 1313\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1314 non-null   int64 \n",
      " 1   동화          1275 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 20.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/dataset.csv', encoding='UTF-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b4366a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"6월 6일은 나라를 지키기 위해 목숨을 바친 모든 이들의 넋을 기리는 법정 기념일 현충일이랍니다.  병자호란 임진왜란을 거치고 또 35년간 일제 강점기를 거치고 또 한국전쟁으로 남과 북이 갈라지고. 이렇게 슬프고 아픈 역사 속에서 우리나라를 지키기 위해 싸우다가 목숨을 잃은 분들이 너무도 많답니다. 우리 모두가 6월 6일 현충일을 맞아서 나라를 위해 목숨을 바친 그리고 나라를 위해 열심히 이름을 빚는 분들에게 더더욱 감사하고 자랑스러운 마음을 가져봤으면 좋겠어요.  그분들이 있기에 지금 우리가 이렇게 편하게 지낼 수 있는 것일 테니까요.  오늘 신나는 동화여행에서는 현충일을 맞아서 나라를 빼앗겼던 일제 강점기 그 시대에 나라를 잃은 슬픔이 얼마나 커다란 것인지 느끼게 해준 세상에서 제일 슬픈 금메달 이야기를 해볼까요.  그럼 신나는 동화 여행에서 달리기 소년 손기정을 만나러 가볼까요.  우리 할아버지입니다. 어려서부터 나는 할아버지와 한 방을 썼어요. 할아버지는 늘 신문을 오려 붙이고 우표책을 정리하셨죠.  할아버지 헌 우표는 뭐하러 모으세요.  신문 오리는 거 재미있으세요. 할아버지는 부지런하고 꼼꼼하셨어요.  할아버지와 저는 사이가 아주 좋았답니다.  에게 스케이트를 사주시고 자전거 타는 법도 가르쳐 주신 게 할아버지거든요. 넘어지는 걸 겁내지 마라 무릎이 까지고 피도 나봐야 잘 달릴 수 있는 거야 할아버지는 늘 이렇게 말씀하셨어요.  몸이 건강해야 마음도 건강해진다고요 운동회 날이면 사람들 속에 할아버지가 늘 서 계셨어요.  할아버지가 지켜봐 주시니까 저는 너무나도 힘이 났죠. 니 앞에 가는 사람은 너만큼 힘들고 니 뒤에 따라오는 사람은 너보다 더 힘들단다 할아버지 말씀 때문에 나는 힘든 줄도 모르고 달릴 수 있었죠.  골목에서 달리기 시합을 하던 날이었어요.  달리기에서 1등을 한 동네 형이 자랑스럽게 말했죠. 이러면 나도 올림픽 마라톤에서 금메달을 딸 거야 옛날에 손기정이라는 사람이 올림픽 금메달을 땄는데 일본 놈들이 자기네 금메달이라고 했대 그래서 손기정이 가슴에 있는 일장기를 우두둑 뜯어내니까 글쎄 가슴에서 태극기가 나왔대 그날 저녁 저녁밥을 먹으면서 그 이야기를 우리 식구들에게 들려줬죠. 그런데 갑자기 식구들이 막 웃는 거예요. 그리고 우리 형이 벽에 걸린 사진을 가리키면서 말했어요.  야 인마 손기정이 누군지 몰라 바로 우리 할아버지야 정말 우리 할아버지가 그 손기정이야? 저는 할아버지랑 이름이 같은 줄만 알았다니까요. 그 사람이 우리 할아버지일 줄은 정말 몰랐어요.  갑자기 할아버지가 멋있어 보였죠. 우리 집에는 오래된 흑백 사진이 걸려 있습니다.  월계관을 쓴 청년이 월개관수를 들고 있는 사진이에요.  저는 그 사진이 그제야 눈에 들어왔어요.  사진 속에 청년이 할아버지라는 것도 베를린 올림픽에서 금메달을 딴 기념 사진이라는 것도 저는 이제서야 알게 되었답니다.  그런데 아무리 봐도 이상해요. 그 사진 말이에요.  할아버지가 억지로 울음을 참고 있는 것 같았거든요.  저는 반에서 달리기 1등을 할 때 하늘을 날 것 같이 기뻤는데 세계에서 마라톤 1등을 하고도 왜 웃지 않았을까요.  저는 너무 궁금해서 할아버지에게 그 이유를 물었어요.  할아버지는 가슴 속에 묻어두었던 이야기를 들려주셨답니다.  우리 조선의 이웃나라 일본은 남의 나라 땅을 빼앗기 위해 조선을 넘보았단다. 기어이 조선 땅을 빼앗은 일본은 조선의 말과 글까지 쓰지 못하게 했지 입이 있어도 말 못하고 귀가 있어도 듣지 못하던 그 시절에 달리 이로 둘째가라면 서러운 조선의 아이가 있었단다 그 아이가 아마 꼭 너만 했을 때였을 거야 압록강을 흐르던 뗏목을 쫓아 들깨처럼 달렸다.  날이 어두워지면 집을 멀리 떠난 두려움에 울먹이며 내달려오곤 했단다 학교 가는 길은 더운 줄도 추운 줄도 모르고 계속 달렸어 어머니가 땀이 밴 단벌 옷을 빨아대다가 한 번은 으름장을 놓았지 달리기만 하려거든 학교 갈 생각도 말아 그리곤 어머니는 일부러 여자 고무신을 사주셨는데 자꾸 신발이 벗겨져서 새끼들로 묻고 달렸지 발등이 까져 피가 났지만 그래도 그 아이는 달릴 때가 제일 행복했단다. 그 아이가 자라 청년이 되었을 때 올림픽 마라톤대에 뽑혀 나갔어 오로지 일본 선수를 이기겠다는 생각 밖에 없었지 그래서 이를 악물고 죽을 힘을 다해 달렸어 달리기만큼은 일본에 지고 싶지 않았으니까. 고통이 발끝에서 머리 끝까지 치밀어 오를 때마다 머리에 보 짐을 인 어머니의 주름진 얼굴을 돌렸고 자신과의 싸움에서 지지 않으려고 날 품팔이하고 허드렛일 하던 시절을 떠올렸지. 두 시간 이십구분 십구초 동안 수없이 지옥을 오가다가 마침내 그 두 다리로 세계를 이기고 말았단다. '야판 기다이손' 우승 국가와 우승자의 이름이 불리는 순간 일본 역사에 영원히 기록될 마라톤 첫 우승이 되었단다 일본 국기를 달고 달렸으니 결국 일본이 일등을 한 꼴이야 그 청년은 시상대에서 얼굴을 들지 못했지 벌럭이는 일장기는 안 보면 되고 옷에 새겨진 일장기는 월개간수로 가리면 됐지만 귓속을 파고드는 일본 국가는 어쩔 수가 없었지 우승의 순간 영광의 그날이 평생 지울 수 없는 아픔이 될 줄 몰랐단다. 일등을 한 사람은 분명 조선 사람인데 일본 국기가 올라가고 일본 국가가 연주되었지. 너라면 기뻐했겠냐. 아니면 슬퍼했겠냐. 할아버지가 울음을 삼키게 된 까닭을 알게 돼서 이번엔 내가 울지도 울지도 못하고 말았어요.  가슴이 먹먹해지고 주먹이 불끈 쥐어졌지. 그 후로 56년 뒤에 할아버지의 후배가 올림픽에 나갔대요 태극기를 휘날리고 애국가를 울리면서 우리나라 이름을 전 세계에 알렸습니다. 나라를 잃은 금메달은 기쁨이 돼서 돌아왔죠 우리 할아버지는 손기정입니다.  금메달을 빼앗긴 슬픈 마라톤 영웅입니다.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['동화'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f665ea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하루는 노인과 그의 아내가 누추한 집 앞에 앉아 잠시 일손을 놓고 휴식들을 취하고 있는데, 난데없이 검정 말 네 마리가 끄는 화려한 마차가 그들 쪽으로 달려오더니 부자차림의 사내 한 명이 내리는 거예요. 농부가 일어나 그 권세가에게 다가가 “뭐 필요하신 거라고 있으신지요?”라고 물었어요. 손님이 노인에게 손을 내밀더니 말했어요. “바라는 건 없습니다, 다만 시골 밥상 한 번 먹어보고 싶군요. 늘 즐겨먹으시던 그 감자 요리 말입니다. 준비해주시겠다면 즐거이 먹겠습니다.” 농부는 미소를 보이더니 말했어요. “네, 아무래도 당신은 백작이거나 왕자님 아니시면 공작이신 모양이군요. 귀족 분들이 종종 그런 음식상을 바라실 때가 있지요, 해드리리다.” 아내가 부엌으로 가 감자를 씻어 갈기 시작하더니 나중엔 둥글게 말아서 시골사람들이 즐겨 먹는 걸 만들었지요. 아내가 바삐 요리를 하는 동안, 농부가 손님에게 말했어요. “잠시 정원으로 드시지요, 제가 아직 해둘 일이 좀 남아서요.” 그는 정원에 구멍 몇 개를 이미 파놓은 상태였던지라, 거기에 나무 몇 그루를 심으려던 참이었지요. “자녀가 없으시군요,”라며 손님이 말했어요. “도와줄 만한 이들은 없는 겁니까?” “네,”라며 농부가 대답했어요. “사실, 아들놈이 한 명 있긴 있었는데, 오래전에 세상으로 나갔죠. 변변치 못한 놈이 머리가 좋고 이해가 빠르다 보니 배우는 게 고작 나쁜 짓들뿐이더군요. 그러다 결국 집을 나가버렸죠, 그 이후론 그 애 소식을 듣지 못했습니다.” 노인은 어린 나무 한 그루를 집더니 땅에 파놓은 구멍 속에다 넣고 그 옆에 말뚝 하나를 때려 박았지요. 그런 다음 흙을 파 넣고 단단히 밟아 주었답니다. 땅 위로 나온 나무줄기를 맨 위와 맨 아래 그리고 중간 이렇게 세 부분을 노끈으로 말뚝과 단단히 묶었어요. “말해주십시오,”라며 손님이 말했어요. “왜 저기 저 구부러지고 울퉁불퉁한 나무는 묶지 않으신 겝니까, 저 구석에 있는 거 말입니다, 아래로 구부러져 거의 땅에 달라붙은 있는 거요, 저 나무도 말뚝을 밖고 세워놓으면 세워지지 않습니까?” 노인이 살짝 미소지어보이더니 말했어요. “나리, 그리 말씀하실 수도 있지요, 아무래도 나리는 정원 일엔 서투시준요. 저기 저 나무는 너무 나이들고 모양이 이미 뒤틀린 후라 누구도 바로 펼 수 없답니다. 나무는 어릴 적에 모양을 잡아줘야 한답니다.” “그게 꼭 아들교육과 같군요,”라며 손님이 말했어요. “어릴 적에 바로잡아주지 않음 싶지 않지요. 지금쯤이면 아드님도 다 커서 흉…해 있겠군요.” “원체 오래전에 나가버린 녀석이라,”라며 노인이 대꾸했어요. “아마 그리돼 있을 겝니다.” “그 애가 다시 돌아온다면 알아보실 방법이라도 있으신지요?”라며 손님이 물었어요.  “얼굴로는 못 알아보지요,”라며 농부가 대꾸했어요. “다만 표식이 하나 있는데, 그 애 어깨 위에 ‘출생 모반’ 하나 나 있습니다. 태어날 때부터 가진 반점이지요.” 그러자 손님이 자신의 외투를 벗더니 어깨를 드러내며 농부에게 그 반점을 보여주었지요. “에구 세상에나!”라며 노인이 소리질렀어요. “정말 내 아들이구먼!” 아들에 대한 사랑에 심쿵한 거지요. “그렇지만,”라며 노인이 덧붙였어요. “어떻게 내 아들이 이리도 귀한 귀족이 되어 풍요를 누리면 산단 말인지? 이게 다 어찌 된 일이더냐?” “아, 아빠,”라며 아들이 대답했어요. “어린 나무는 어릴 적에 말뚝에 묶어두지 않음 자라면서 구부러지죠, 이제 그 나무는 너무 나이 들어 다시 펴지지 않는 답니다. 그러니 전 어떻겠습니까? 전 이제 도둑이 되었습니다, 그것도 최고의 도둑이요, 놀라지 마세요. 이제 제겐 열쇠든 자물쇠든 다 필요 없답니다, 제가 원하기만 하면요. 저는 흔한 도둑들처럼 훔치지 않습니다, 저는 부자들의 남아도는 재산만 적당히 훔치거든요. 가난한 사람들 건 손도 대지 않습니다, 차라리 제가 그들에게 나눠줄 정도죠. 문제 될 거 같은 돈은 아예 손대 되지 않죠, 일단 손을 대면 절묘하고 빈틈없이 훔친답니다.” “아아, 내 아들아,”라며 아빠가 말했어요. “전혀 즐겁게 들리지가 않는구나, 도둑은 그냥 도둑일 뿐이란다, 내가 말해주고 싶은 건 도둑들의 끝은 순탄치 않다는 게다.” 그래도 아빠는 아들을 데리고 엄마에게 갔어요. 그녀는 그게 자신의 아들이란 소릴 듣곤 기뻐서 울었어요. 하지만 아들이 최고의 도둑이 되었다는 말엔 저도 모르게 얼굴 위로 두 줄기 눈물이 또르르 흐르고 말았죠. 마침내 엄마가 말했어요. “도둑이 됐다만, 그래도 내 장한 아들을 이 두 눈으로 다시 보니 좋구나.” 그들은 식탁에 앉았어요.  그리고 그는 한동안 먹지 못했던 그 초라한 음식을 부모님과 함께 다시 들었답니다. 아빠가 말했어요.  “저 성에 사시는 우리 주인, 백작님이 네가 커서 도둑이 될 줄 알았다면, 네 세례식 때 품에 널 안아주지 않았을 게다, 지금 들켰다간 단번에 널 교수대에 매달아 처형시킬 게다.” “좋게 생각하세요, 아빠, 그는 저를 어쩌지 못해요, 왜냐면 저만이 제 기술을 알고 있거든요. 더구나 오늘 바로 그를 찾아가볼 생각이고요.” 저녁놀이 질 무렵, 최고의 도둑은 자신의 마차를 타고 그 성으로 향했어요. 백작이 그를 정중하게 맞이했어요, 왜냐면 그를 저명한 인물로 착각했거든요. 하지만 손님이 자신을 소개하자, 백작의 얼굴이 창백해지면 잠시 말문을 뚝 닫아버리더군요. 마침내 백작이 말했어요.  “당신은 내 ‘대자’ 니, 정의 대신 자비를 베풀어, 후히 대해주리다. 하지만 최고의 도둑이 되셨다 그리도 자긍심에 취해 있으시니 내 시험을 한 번 내보리다. 만약 통과하지 못하면 당신은 밧줄 제조자의 딸과 결혼하게 될 거요, 그럼 까마귀들의 축하 노래를 듣게 될 게요.” “백작님,”라며 최고의 도둑이 대답했어요. “당신만큼이나 곤란한 세 가지를 생각해보시지요, 그럼 제가 하나씩 풀어보리다, 당신이 바라시는 대로 말입니다.” 백작이 몇 분 동안 생각하더니 말했어요. “그럼, 우선, 내가 즐겨 타는 말을 훔쳐보시오, 내 마구간에서 말이오. 두 번째로, 내가 아내와 깔고 자는 침대 시트를 훔쳐보시오, 그것도 우리가 잠든 사이, 발각되지 않고 말이오, 덤으로, 아내가 낀 결혼반지도 훔쳐야하오. 마지막 세 번째로, 교회에서 목사님과 집사님을 훔쳐오시오. 내 미리 말해두는데, 목숨을 담보로하시는 일이니 신중히 잘 해보시구려.” 최고의 도둑은 가장 가까운 마을로 갔어요. 거기서 그는 농부할머니의 옷들을 사 입었어요. 그런 다음 얼굴을 갈색으로 칠하고 또한 살에 주름살도 그렸어요. 그랬더니 그 누구도 그를 알아보지 못했답니다. 그런 다음 그는 작은 통을 오래된 헝가리 포도주로 잔뜩 채웠는데 강력한 수면제도 같이 섞었답니다. 그는 그 술통을 바구니에 담아 어깨에 짊어 메고는 천천히 비틀비틀 백작의 성으로 향했어요. 그가 도착했을 땐 이미 날이 어둑어둑한 후였지요. 그는 안마당의 돌 위에 앉아 콜록콜록 기침을 했어요. 마치 천식에 걸린 노파처럼 말이죠. 그러면서 춥다는 듯 연신 두 손을 비벼댔답니다.  마구간 정문에 병사 몇몇이 모닥불을 피워놓고 둥글게 앉아 있었지요. 그들 중 한 명이 할머니를 발견하더니 소리쳐 불렀어요. “이리 오세요, 몸 좀 녹이세요, 할머니. 오늘밤 묵으실 만한 곳이 없음 이만한 곳도 없지요.” 노파가 비틀거리며 그들 쪽으로 가더니 등에 짊어지고 있던 바구니를 그들 앞에 내려놓았어요. “그 작은 통엔 뭐가 든 겝니까, 노부인?”라며 한 병사가 물었어요.  “맛좋은 포도주요,”라며 그녀가 대답했어요. “그걸로 먹고 살거든요, 돈을 주시거나 말씨를 이쁘게 하면 내 기꺼이 여러분들께도 한 잔씩 드리리다.” “그거라면 우리들만 한 게 없지, 자 여기,”라며 그 병사가 말했어요.  그가 한 잔 맛을 보더니 말했어요. “그 참 포도주 기가 막히네, 완전 꿀맛이야, 한 잔만 더 주쇼.” 그렇게 또 한잔을 채우니 옆에 있던 무리들이 덩달아 자신들도 좀 맛 좀 보자고 말하고 나섰어요. “이보게, 동료들,”라며 그들 중 한 명이 마구간에 있는 병사들에게 큰소리로 말했어요. “이리와 보게. 여기 정말 할머니 연세만큼이나 오래되고 맛좋은 포도주가 있다네. 목도 좀 축이고, 위도 따뜻하게 했더니 이거 원 모닥불보다 훨 낫구먼.” 노파가 자신의 술통을 들고 마구간 안으로 들어갔어요. 병사들 중 한 명은 이미 안장이 매어진 말에 앉아 있었어요. 그리고 또 한 병사는 손으로 말의 고삐를 쥐고 있었고요, 세 번째 병사는 두 손으로 말의 꼬리를 꼭 붙잡고 있었답니다. 그녀가 술통이 바닥을 보일 때까지 삭다 비워가며 그들을 퍼 맸었어요. 머지않아 말의 고삐를 잡고 있던 병사의 손이 뚝 떨어지더니 그가 쓰러지며 쿨쿨 코를 곯기 시작했어요. 말의 꼬리를 손으로 잡고 있던 다른 병사도 바닥에 드러누우며 앞서 병사보다 훨씬 크게 코를 곯기 시작했지요. 말의 안장에 앉아있던 병사만은 그래도 여전히 앉아 있었는데, 이미 고개를 말의 목에 닿을 듯 푹 숙인 상태로 마치 대장간의 고함소리처럼 입에서 크아크아 소리를 내뿜으며 자고 있었죠. 밖에 있던 병사들은 이미 한참 전에 모두 바닥에 드러누워 자느라 꿈쩍도 하지 않고 있었죠, 모르는 사람이 보면 죽은 줄 알 정도로 말이죠. 성공이 눈앞에까지 온 최고의 도둑은, 우선 말의 고삐를 잡고 있었던 그 병사의 손엔 다른 줄 하나를 쥐어주고, 말의 꼬리를 붙잡고 있었던 병사의 손엔 말을 씻는 짚수세미를 하나 쥐어주었지요. 그럼 말안장에 저렇게 끝까지 앉아 있는 저 병사는 어찌해야할까요? 그는 그렇다고 그 병사를 바닥에 패대기치고 싶진 않았어요. 그랬다간 그 병사가 깨서 고함을 지르며 일을 그르칠 테니까요. 그때 좋은 생각이 떠오른 그가 말안장의 배띠를 풀어 벽에 걸린 고리에다 단단히 끈 두서너 개로 단단히 묶었죠. 그런 다음 자고 있는 병사를 살살 들어 기둥에다 붙이고 줄로 꽁꽁 묶어놓았죠. 말을 묶고 있던 줄도 금방 풀었답니다. 하지만 이대로 돌로 포장된 마당으로 말을 타고 나갔다간 온 성 전치에 소리가 다 들릴 테니, 그는 일단 말의 발굽들을 낡은 헝겊들로 감싸고 조심스레 말을 밖으로 끄집어내 올라탄 다음 총총 사라졌지요. 날이 밝자, 최고의 도둑은 훔친 말을 타고 성으로 전속력으로 달려왔어요. 막 깨어난 백작이 그 광경을 창문을 통해 다 보게 되었지요. “좋은 아침입니다, 백작 나라,”라며 최고의 도둑이 소리쳤어요. “여기 당신의 말이 있습니다, 제가 어제 마구간에서 안전하게 훔쳐 내온 거지요! 한번 가 보십지요, 당신의 병사들이 얼마나 곤히 잠들어 있는지를요. 특히 마구간에 가보시면, 당신의 파수꾼들이 얼마나 곤한 휴식을 취하고 있는지를 보시게 될 겁니다.” 백작은 그저 웃을 수밖에 없어 말했어요. “일단 이번 시험은 성공적으로 통과했네, 하지만 두 번째 난간은 쉽지 않을 걸세. 내 미리 경고하건데 자네가 내 앞에 도둑으로 나타나는 순간 난 자넬 한 명의 도둑으로 대우할 걸세.” 백작의 부인이 그 날 침대로 가 결혼반지를 손으로 꼭 감싸 안으며 잠이 들었답니다. 백작이 말했지요. “문이며 열쇠며 빗장이며 모두 잠갔다오, 게다가 난 그 도둑이 올 때까지 자지 않을 거요, 그는 저 창문으로만 들어올 수 있을 테니, 내 그때를 기다려 총을 쏘아 맞추리다.” 하지만 최고의 도둑은 밤이 되자 우선 교수대들로 가 매달려 있던 불쌍한 죄인 한 명을 바닥으로 내려뜨린 다음 등에 짊어매고 그 성으로 향했어요. 그런 다음 그는 사다리를 침실에 대고 타고 올라가는데, 우선 죽은 자의 머리가 그의 어깨 위에 오게 해 올라갔답니다. 그가 어느 정도 높이까지 올라가자 죽은 자의 머리가 창문에 보였어요, 침대에서 이를 지켜보고 있던 백작이 권총을 발사했지요. 그 즉시 최고의 도둑은 그 불쌍한 죄수를 바닥에 떨어뜨리곤 자신도 구석에다 몸을 숨겼어요. 밤이었지만 달빛에 환했거든요, 그래서 최고의 도둑은 백작이 창문에 댄 그 사다리를 통해 내려오는 모습을 똑똑히 관찰할 수 있었죠. 백작은 다 내려오더니 죽은 자의 시신을 정원으로 끌고 가더니 아무래도 묻으려는 생각인지 땅에 구멍을 파기 시작했지요. ‘이제야,’라며 최고의 도둑이 생각했지요. ‘기회가 찾아왔군.’ 그는 구석에서 재빨리 나와 사다리를 타고 곧장 백작 부인의 침실로 들어갔어요. “여보,”라며 그가 백작 목소리를 흉내 내며 말하기 시작했어요. “도둑이 죽었다오, 하지만 무엇보다 그는 내 ‘대자’ 였지 않소, 그래서 악당보단 밥벌레에 가깝던 사람인데, 땅엔 묻어주고 싶더군. 그래야 그의 부모님들께도 안 미안할 테고. 동일 트기 전에 묻어줄 생각이오, 남몰래 정원에 말이오. 내게 침대시트를 주시구려 그럼 내가 그를 그걸로 감싸 강아지처럼 묻어주리다.” 백작부인이 침대시트를 건네주었어요. “그리고,”라며 최고의 도둑이 계속 말했어요. “그 반지도 내게 주시구려… 저 세상으로 가는 자의 무덤에 그거 하나라도 가져가라 말하고 싶어서 그러오.” 아내가 반박하려다 말고 손가락에서 반지를 꺼내 남편에게 건네주었어요. 도둑은 이 두 가지를 챙기고서 정원에서 땅 파는 백작이 작업을 다 마치기 전에 집에 안전하게 도착했답니다. 다음날 아침 최고의 도둑이 침대시트와 반지를 들고 나타났을 때, 백작의 긴 얼굴이 뻘쭘해지고 말았지요. “당신 마법사요?”라며 백작이 말했어요. “내가 분명 자넬 땅에 묻었는데, 어찌 살아난 게요?” “저를 묻으신 게 아니라,”라며 최고의 도둑이 말했어요. “교수대 죄인을 묻으신 겁니다.” 그가 자초지종을 백작에게 말해주었지요. 그러자 백작도 “자네 정말 똑똑하고 교활한 도둑이군.”라며 인정하지 않을 수 없었죠. “하지만 아직 하나 남았네,”라며 백작이 덧붙였어요. “자넨 세 번째 임무도 마저 수행해야하네, 그걸 완수하지 못하면 말짱 헛수고지.” 최고의 도둑은 미소를 지으며 아무런 말이 없었죠. 밤이 깔리자, 최고의 도둑이 등에 기다란 자루를 이고 겨드랑이에도 한 보따리 짐을 끼고 손에 손전등 하나만 켜고 교회묘지로 들어갔어요. 자루에는 ‘게’ 를 넣어가지고 갔고, 보따리엔 짧은 양초들을 담아가지고 갔지요. 그가 묘지에 앉더니 게 한 마리를 꺼집어 내 게의 등딱지에 양초를 붙였어요. 그런 다음 그가 그 짧은 양초에 불을 붙이곤 게를 땅바닥에 놓아주어 게가 이러 저리 기어 다니게 놓아두었어요. 그는 자루에서 두 번째 게도 꺼내더니 똑같은 방식으로 처리한 다음 자루에서 마지막 게를 꺼낼 때까지 반복했어요. 여기에 잇따라 그는 마치 수도사의 겉옷처럼 생긴 긴 검정 옷을 입고 턱엔 회색빛깔 턱수염도 하나 붙였지요. 결국 완벽한 변장에 성공한 그가 게들을 넣었었던 그 자루를 도로 집어 들곤 교회로 들어가 설교단으로 올라갔답니다. 탑에 있는 시계가 막 밤12시를 치고 있었죠. 마지막 종이 울리는 가운데, 최고의 도둑의 우레와 같고 찢어지는 듯한 목소리가 울려 퍼졌답니다. “경청하라, 죄 많은 자들아, 종말이 도래했도다! 최후의 날이 왔도다! 경청하라! 경청하라! 천국에 들길 바라는 자 자루 속으로 기어들지니. 난 천국의 문을 열고 닫는 베드로니라. 바꺝 교회 묘지에 죽은 자들이 헤매며 자신들의 뼈들을 모으고 있노라. 자, 어서, 이 자루로 기어들라. 세계의 파멸이 이제 막 도래하려하노니!” 그 고함소리는 온 마을에 울러퍼졌지요. 목사님과 집사님은 때마침 교회 가장 가까이에서 살고 있다 제일 먼저 그 고함소리를 듣게 되어 밖을 내다보았더니 정말로 불빛들이 교회 묘지를 이리저리 움직이고 있는 지라, ‘기어이 사단이 벌어졌구나!’라고 생각하기에 이르러 급히 교회로 들어갔지요. 그들은 잠시 설교를 들었어요.  그때 집사님이 목사님을 팔꿈치로 슬쩍 찌르며 말했어요. “최후의 날이 밝기 전에 함께 천국에 드는 것도 나쁘진 않습니다요.” “진실로,”라며 목사님도 대답했어요. “제 생각도 그러합니다. 그럼 당신 생각도 그러하다면, 우리 함께 거기로 가봅시다.” “네,”라며 집사님이 대답했어요. “그럼 목사님께서 먼저 앞장을 서시지요, 제가 따라 가리다.” 그리하여 목사님께서 먼저 설교단으로 오르셨고, 최고의 도둑이 자루를 벌려주자, 그 속으로 기어들어가셨어요. 그런 다음 집사님도 따라서 자루 속으로 들어갔지요. 최고의 도둑은 그 즉시 자루를 단단히 묶고는 가운데를 붙잡곤 설교단 계단을 퉁퉁 밟으며 내려왔어요. 두 바보님들의 머리가 계단에 퉁퉁 부딪힐 때마다 최고의 도둑이 소리쳤지요. “우린 지금 산들을 넘고 있노라.” 그런 다음 최고의 도둑은 똑같은 방식으로 자루를 마을로 끌고 가다 물웅덩이들이 나올 때면 이렇게 소리쳤지요. “우린 지금 젖은 구름들 속을 지나고 있노라.” 마침내 그가 자루를 끌고 성의 계단에 오를 때는 이렇게 소리쳤지요. “우린 지금 천국의 계단을 오르고 있다네, 곧 천국의 바깥뜰에 다다를 수 있을 걸세.” 꼭대기 층까지 올라온 그가 자루를 비둘기장에 집어넣었고, 비둘기들이 푸드덕거리며 날뛰자 그가 말했지요. “들어보거라, 천사들이 얼마나 반기는지, 그들의 날갯짓 소리로 진동을 하는구나!”  그런 다음 그는 문을 닫고 나왔지요. 다음날 아침 그가 백작에게 가 “세 번째 임무도 완수했습니다. 목사님과 집사님을 교회에서 데리고 왔습니다.”라고 말씀드려졌지요. “아니 그들을 어디다 둔 거요?”라며 백작이 물었어요.  “그들은 지금 2층 비둘기…장에 있는 자루 안에 있습니다. 자신들은 지금 천국에 와 있노라 확신하고 있지요.” 백작이 일어나 몸소 가보니 최고의 도둑이 한 말이 모두 다 사실이었어요. 백작은 가둬져 있던 목사님과 집사님을 풀어준 다음 최고의 도독에게 말했지요. “당신은 정말 최고의 도둑이오, 내기에서 당신이 모두 이기셨소. 내 이번엔 당신을 무사히 보내줄 테니 다신 내 땅을 밟지 마시오, 안 그랬다간 교수대의 이슬로 사라질지 아시구려.” 최고의 도둑은 자신의 부모님께 작별인사를 한 다음 드넓은 세상 속으로 다시 한 번 출발했답니다. 그의 이후 소식에 대해선 아무도 전해들은 바가 없었다고 하네요.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df['동화'])):\n",
    "    text = str(df['동화'][i])\n",
    "    full_text = ''.join(text)\n",
    "    \n",
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1b1927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8675"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b23eb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        우리 친구들은 미술이 뭐라고 생각하나요.  종이에 그림을 그리는 것 아니면 멋진 ...1       2022년 5월 5일은 방정환 선생님이 어린이날을 만든 지 100주년이 되는 날이랍...2       5월은 가정의 달이라고 할 만큼 가족들의 소중함을 생각해보게 하는 기념일이 참 많은...3        우리 친구들은 또래 친구들을 만나면 보통 어떤 놀이를 하면서 시간을 보내나요?  ...4       6월 6일은 나라를 지키기 위해 목숨을 바친 모든 이들의 넋을 기리는 법정 기념일 ...                              ...                        1309    옛날에 한 번은 마부가 포도주를 잔득 실은 ‘달구지’를 끌고 가다 그만 속도를 너무...1310    어느 커다란 도시에 나이 드신 어머님 한 분이 자신의 방에 저녁 내내 앉아 그동안 ...1311    가난한 시골 소년이 어느 날 교회에서 목사님이 “하늘나라 왕국에 들어가길 원하는 자...1312    어느 날 오후에 아기 예수가 아기침대에 누워 잠을 자고 있었답니다. 그때 그의 어머...1313    하루는 노인과 그의 아내가 누추한 집 앞에 앉아 잠시 일손을 놓고 휴식들을 취하고 ...Name: 동화, Length: 1314, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11950256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Corpus lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spliting Lines: 100%|███████████████████████████████████████████████████████████| 1684/1684 [00:00<00:00, 19580.43it/s]\n",
      "Corpus Sampling: 100%|████████████████████████████████████████████████████████████| 1684/1684 [00:04<00:00, 411.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training kor2vec\n",
      "Loading Word_sample corpus\n",
      "Loading corpus finished\n",
      "CUDA Available/count: False 0\n",
      "training on  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 0: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:09<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'train_ep_loss': 1.3606191934478853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 1: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:29<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_ep_loss': 1.278075259866231}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 2: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:27<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'train_ep_loss': 1.2550210904389416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 3: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:56<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 3, 'train_ep_loss': 1.2401307852841184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 4: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:35<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'train_ep_loss': 1.2291084816488427}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 5: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:33<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'train_ep_loss': 1.2205206501999857}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 6: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:28<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 6, 'train_ep_loss': 1.2051391882104863}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 7: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:28<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 7, 'train_ep_loss': 1.197156763361907}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 8: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:27<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 8, 'train_ep_loss': 1.1876988652626854}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP 9: 100%|████████████████████████████████████████████████████████████████████████| 3512/3512 [06:30<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 9, 'train_ep_loss': 1.178092176930508}\n"
     ]
    }
   ],
   "source": [
    "from kor2vec import Kor2Vec\n",
    "\n",
    "kor2vec = Kor2Vec(embed_size=128)\n",
    "\n",
    "kor2vec.train(\"dataset/dataset.csv\", \"model.kor2vec\", batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a33099",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor2vec.save(\"embedding_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c39830",
   "metadata": {},
   "source": [
    "## 1. Bias Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff12e6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9792e-01,  4.6852e-01, -6.2760e-01,  8.0020e-01, -9.0955e-01,\n",
       "         -5.9727e-01, -8.2120e-01, -5.7056e-01, -2.5505e-01, -5.9409e-01,\n",
       "          8.8992e-01,  1.4842e+00, -2.9688e-01, -4.2640e-01, -5.9283e-01,\n",
       "         -1.4650e-01,  5.2687e-01,  9.0604e-01,  1.4035e+00, -5.7625e-01,\n",
       "         -3.7729e-01,  9.6969e-01,  8.2274e-01, -1.1566e+00,  6.7213e-02,\n",
       "         -8.3325e-01, -7.8475e-01,  2.1273e-01,  5.6653e-01, -1.4982e-01,\n",
       "          3.1909e-01, -7.3094e-01,  7.1949e-01,  5.6684e-01,  1.1343e+00,\n",
       "         -7.4837e-01, -5.5475e-01,  1.0884e+00, -1.5542e-01, -3.8770e-01,\n",
       "         -4.9190e-01,  1.2128e-01, -1.0822e-01,  1.2499e-01,  1.0427e-02,\n",
       "          1.4682e+00,  9.9037e-01, -3.1604e-01,  1.3287e-01, -1.3185e+00,\n",
       "         -1.8763e-02, -5.9029e-01,  5.2883e-01,  3.7427e-01,  7.9970e-01,\n",
       "         -5.8155e-02,  4.4877e-01, -1.2376e-03, -8.2393e-01,  2.2272e-01,\n",
       "          7.7622e-01,  9.8738e-01, -4.3114e-01, -4.9727e-02, -3.9917e-01,\n",
       "          1.0586e+00,  1.1407e+00,  5.7288e-01,  3.5844e-01,  9.3884e-01,\n",
       "          3.9454e-01, -1.7816e-01,  4.1969e-01,  6.3125e-01,  3.4831e-01,\n",
       "          4.4980e-01, -1.0853e+00, -4.3180e-02,  3.3800e-01, -9.4804e-01,\n",
       "          1.4483e+00, -1.4175e-02,  2.2918e-01, -3.9446e-01,  7.8110e-01,\n",
       "         -9.4119e-02, -7.6365e-02,  1.0937e-01,  2.8338e-01,  5.2933e-01,\n",
       "         -2.6012e-01, -6.2163e-01,  1.8236e-01, -3.8072e-01, -1.3494e-01,\n",
       "         -7.2709e-01,  3.2901e-01,  5.0273e-01, -4.1535e-01,  2.7481e-01,\n",
       "          7.7609e-01,  8.1003e-01, -4.9756e-01, -1.3464e-01,  3.1613e-01,\n",
       "         -1.2233e+00,  4.1726e-01, -3.0395e-01, -3.8610e-01, -6.6568e-01,\n",
       "         -5.4303e-01, -1.5119e+00,  1.3355e+00, -1.5404e-01, -3.0277e-01,\n",
       "         -5.0921e-01,  5.4743e-02, -1.5393e-01,  1.6144e-01,  5.0292e-01,\n",
       "          2.8473e-01,  3.7759e-01,  9.1635e-02,  2.9400e-01,  6.5823e-01,\n",
       "          3.7230e-01, -8.2773e-01,  5.2423e-02],\n",
       "        [-4.7005e-04,  1.2680e-01, -1.7242e-01, -2.0019e-01,  3.6472e-01,\n",
       "         -9.5397e-02, -1.1855e-01, -1.1947e-01,  7.6824e-01, -7.2358e-02,\n",
       "          5.7150e-01, -1.1503e-01, -1.9685e-01, -2.4500e-01, -1.7168e-01,\n",
       "         -1.8335e-01, -1.5430e-01,  6.3592e-01, -1.6384e-01, -2.1657e-01,\n",
       "          9.8421e-02, -2.6428e-01, -1.5270e-01, -1.8074e-01, -1.8611e-02,\n",
       "         -1.0083e-01,  5.5264e-01,  9.3191e-01, -1.6321e-01, -1.8141e-01,\n",
       "         -7.9101e-02, -2.6775e-01, -3.8175e-01,  9.4463e-02,  4.7806e-02,\n",
       "          1.7872e-02, -2.9943e-01, -6.5185e-01,  1.5323e-01,  2.3998e-02,\n",
       "         -5.9165e-01, -5.7814e-01, -8.8488e-02,  2.5571e-01, -1.7255e-02,\n",
       "         -3.0841e-01, -3.0720e-01,  1.0095e-01,  4.5907e-02,  1.3143e-01,\n",
       "         -1.5306e-01, -2.7972e-01,  5.7830e-01, -3.2071e-01,  3.0720e-01,\n",
       "         -3.9469e-01, -1.0261e-01,  3.7665e-01,  5.4726e-01, -4.0486e-01,\n",
       "         -2.3776e-01, -4.8168e-01, -3.1397e-02, -1.2619e-01,  1.0108e-01,\n",
       "         -2.2825e-01, -7.1108e-02, -2.1937e-01, -3.7079e-01,  2.9232e-03,\n",
       "         -3.8548e-01,  5.9628e-01, -9.3958e-02, -6.5321e-01,  2.8043e-01,\n",
       "         -5.2176e-01, -3.5040e-01, -2.7472e-01, -4.6749e-02,  2.2815e-01,\n",
       "          8.5770e-01,  1.6821e-01, -4.0630e-01,  1.8665e-01,  1.2742e-01,\n",
       "          1.7454e-01,  6.9705e-01, -4.4812e-01,  1.5639e-02, -8.7373e-02,\n",
       "         -5.6200e-01, -1.7383e-01,  4.9448e-01,  2.4818e-01,  5.0189e-01,\n",
       "         -4.6011e-02,  9.9038e-03,  2.2578e-01,  2.8780e-01,  6.4759e-01,\n",
       "          1.1922e-01, -6.1359e-01, -1.4101e-01,  6.4503e-02,  5.0125e-02,\n",
       "         -3.6016e-01,  3.4614e-01,  4.2410e-01,  4.5966e-01, -2.3017e-01,\n",
       "          2.2748e-01, -7.4086e-01,  4.4191e-01, -1.2185e-01, -7.5211e-01,\n",
       "          2.4132e-01,  6.0382e-01, -5.2278e-02, -6.5511e-01, -2.0725e-02,\n",
       "         -4.3989e-01,  4.7851e-01,  2.3255e-01, -1.2313e-01, -8.8381e-02,\n",
       "          7.3889e-01, -1.8272e-01,  1.7155e-01],\n",
       "        [-3.5412e-01,  1.5144e-01,  3.7030e-01, -3.4096e-01, -6.8104e-02,\n",
       "         -1.8728e-01,  2.1806e-01, -3.0661e-01, -5.0028e-01, -9.2448e-02,\n",
       "          3.9283e-01,  1.5330e-02, -2.5144e-02, -2.4476e-01, -1.6924e-01,\n",
       "          8.6930e-02,  4.2249e-01,  2.5100e-01,  8.8671e-02,  1.7603e-03,\n",
       "          8.0667e-01,  1.7779e-01, -6.2810e-02, -1.7662e-01,  3.5215e-02,\n",
       "         -1.5286e-01,  8.0497e-01,  8.1342e-03,  2.0168e-01,  1.3577e+00,\n",
       "          6.0030e-01, -5.5187e-01,  4.6443e-01,  9.3912e-01, -4.1051e-01,\n",
       "          9.6709e-02,  3.9250e-01, -2.6838e-02,  3.5170e-02,  4.0702e-01,\n",
       "          3.0194e-02, -8.5846e-02,  1.0667e-01,  2.0794e-01, -5.1181e-01,\n",
       "         -2.1868e-01, -6.8285e-02, -5.9181e-01, -5.2215e-02,  8.7345e-01,\n",
       "          5.0695e-01, -8.1295e-02, -8.6284e-04, -3.0697e-01, -4.1827e-02,\n",
       "         -2.5965e-01, -7.0608e-02,  1.5052e-01, -6.1280e-02, -2.5582e-01,\n",
       "         -3.4390e-01,  2.4173e-01, -2.2824e-01,  2.7370e-01, -3.5443e-01,\n",
       "          4.9506e-01, -3.4139e-02,  1.3384e-01,  1.4753e-01,  6.3805e-03,\n",
       "          7.2286e-01,  4.0818e-03,  7.8931e-01,  3.7984e-01,  1.9984e-01,\n",
       "          4.6690e-01, -4.0727e-01, -3.8403e-03, -7.2301e-02, -1.5506e-01,\n",
       "          2.1136e-01, -2.6023e-01, -1.1665e-01,  5.6034e-01, -2.4387e-01,\n",
       "         -6.9091e-01,  2.1436e-01, -3.0836e-01, -2.6252e-01, -1.4463e-01,\n",
       "         -2.2747e-01, -2.8709e-01, -8.0851e-02,  2.4409e-01,  3.1313e-01,\n",
       "          1.1458e-02, -3.5376e-01,  1.3263e-01,  5.7184e-01, -2.8882e-01,\n",
       "         -4.1152e-01, -6.9077e-02, -5.8592e-01,  4.8607e-01,  3.9919e-01,\n",
       "          1.7806e-01,  6.7653e-02,  2.4949e-01,  1.9703e-02, -6.6032e-01,\n",
       "         -2.5502e-02, -3.5259e-01,  1.6403e-01, -1.6454e-02, -6.3710e-01,\n",
       "          1.1334e-02,  1.9349e-02, -5.1651e-01, -8.3687e-01, -4.7580e-01,\n",
       "         -3.5606e-01,  8.0442e-02, -7.6872e-02,  1.3411e-01,  2.5157e-01,\n",
       "         -1.3839e-01, -1.0538e-02, -1.3678e-01],\n",
       "        [-1.4633e-01, -5.3284e-02, -1.7242e-01, -2.0019e-01, -2.6062e-01,\n",
       "         -9.5397e-02, -1.1855e-01, -4.5459e-02, -1.1179e-01, -1.0778e-01,\n",
       "         -4.5395e-02, -1.5079e-01,  1.5615e-01, -3.3170e-02, -1.7168e-01,\n",
       "         -1.8335e-01, -1.8761e-01, -1.9012e-01, -1.6384e-01, -3.0284e-01,\n",
       "         -1.9189e-01, -3.3786e-02, -1.5270e-01, -1.8074e-01, -1.3349e-01,\n",
       "         -2.2162e-01, -8.6444e-02, -2.0143e-01,  2.7882e-01, -7.5817e-02,\n",
       "          5.2514e-01, -2.6775e-01,  3.2237e-02, -9.0209e-02, -6.2324e-02,\n",
       "         -1.0871e-01,  7.5554e-02, -2.0531e-01, -6.2125e-02,  3.4589e-01,\n",
       "         -1.5147e-01, -1.3725e-01,  1.7758e-01,  5.0139e-01, -1.7829e-01,\n",
       "         -9.2997e-02, -2.9137e-02,  7.2806e-01, -4.1742e-02, -3.9718e-02,\n",
       "         -1.3553e-01, -2.2825e-02, -1.9064e-01, -2.9197e-02,  2.3916e-02,\n",
       "         -1.1493e-01, -6.3534e-02, -1.8555e-01, -2.4749e-01, -2.1422e-01,\n",
       "          6.6204e-01,  1.2673e-01, -1.9120e-01, -2.3737e-01, -2.6951e-01,\n",
       "         -1.5368e-01, -3.1580e-01, -4.4096e-01, -1.0216e-01,  1.0197e-01,\n",
       "         -2.9697e-01, -1.6615e-01, -7.8373e-02, -4.9409e-01, -1.3997e-01,\n",
       "         -2.5520e-01, -8.9975e-02,  1.9882e-02,  3.1330e-01,  7.6793e-02,\n",
       "         -2.8663e-01, -2.9449e-01, -1.6370e-01,  1.0032e-01,  1.7841e-01,\n",
       "          2.8640e-01, -1.8941e-01, -4.3409e-02, -2.0786e-01,  7.7215e-02,\n",
       "          7.0819e-02, -2.1281e-01, -1.9967e-01, -2.2319e-01,  9.2478e-02,\n",
       "          5.6958e-02,  2.7919e-02, -9.6714e-02,  5.2093e-01, -2.6014e-01,\n",
       "         -2.7173e-01, -1.3881e-01, -2.9904e-01, -4.2257e-01,  4.7271e-01,\n",
       "          2.0946e-01, -1.6344e-01,  3.2265e-01,  5.7806e-02,  1.0588e-01,\n",
       "          3.0923e-01,  2.3918e-01,  1.0615e-01, -3.2631e-02,  1.2155e-01,\n",
       "          9.7806e-02, -4.6834e-01, -1.9462e-01,  3.5296e-01,  1.1105e-01,\n",
       "         -6.4960e-02, -4.0042e-01, -1.8260e-01,  2.1093e-01, -4.1988e-02,\n",
       "          3.4548e-02, -6.2502e-02,  9.0819e-02],\n",
       "        [-4.0889e-01,  1.5259e-01, -7.0686e-01, -2.3292e-01, -4.5802e-01,\n",
       "         -3.2094e-02,  2.3478e-01,  2.6363e-01, -1.0010e-01,  2.6149e-02,\n",
       "         -1.3278e-01, -4.6550e-01, -4.5946e-02, -2.7667e-01,  2.5656e-01,\n",
       "         -5.1319e-01, -5.6852e-02, -1.0689e-01, -5.2203e-02,  4.2091e-02,\n",
       "         -5.5025e-01, -4.1442e-01, -2.8370e-01, -1.1492e-01, -1.7882e-01,\n",
       "         -2.3429e-01, -2.3392e-01, -1.7849e-01, -1.4926e-02, -1.0947e-01,\n",
       "         -1.0607e-01, -3.3513e-01,  9.3797e-02, -4.0291e-01,  5.5922e-01,\n",
       "          1.2759e-01, -1.4250e-01,  7.3086e-02, -1.5604e-01,  1.1765e+00,\n",
       "         -3.4794e-01, -2.4117e-01,  5.2546e-01,  9.3229e-01, -5.9406e-02,\n",
       "         -3.8098e-02, -5.4704e-01,  7.0828e-01, -6.3655e-01,  3.2466e-02,\n",
       "         -6.4777e-01, -4.7711e-01, -5.6745e-01,  4.9716e-01,  2.2144e-01,\n",
       "         -4.6162e-01,  3.6607e-01, -3.4226e-01, -7.3028e-02,  2.2194e-02,\n",
       "          6.6523e-01,  9.8473e-02,  3.6258e-01,  7.3862e-02, -6.1267e-01,\n",
       "          3.5690e-01, -1.8822e-01, -9.5808e-02, -2.5519e-01,  2.3942e-01,\n",
       "          1.5994e-01, -1.6572e-01, -2.6175e-01,  4.6449e-01, -2.2911e-01,\n",
       "          1.2459e-01, -3.8225e-01,  2.0730e-01, -1.8687e-01,  3.2777e-02,\n",
       "         -8.5278e-01,  3.6602e-01,  3.3041e-01,  2.6350e-01,  9.6365e-02,\n",
       "         -2.2600e-01,  1.4643e-02,  1.6111e-01, -5.4134e-01,  4.3016e-01,\n",
       "          5.3195e-02, -1.3276e-01, -3.1308e-01, -8.5693e-01, -7.0952e-02,\n",
       "         -6.5768e-01, -2.5608e-01, -1.1215e-01,  1.3650e-02, -1.5508e-01,\n",
       "          1.8034e-01,  2.1484e-01, -4.4579e-01, -3.3924e-01,  2.5586e-01,\n",
       "          5.6597e-01, -1.8565e-01,  5.6310e-01, -4.4725e-02, -2.6292e-01,\n",
       "          2.6130e-01,  3.4902e-02,  8.1039e-02,  4.3887e-02, -1.0116e-01,\n",
       "          3.6881e-01,  6.7012e-01,  3.8271e-01,  8.9009e-01,  3.0549e-01,\n",
       "          1.9735e-01, -7.9170e-02,  1.9315e-01, -4.0195e-01,  2.9629e-01,\n",
       "          2.7336e-01,  1.0164e-01,  7.9428e-02]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kor2vec import Kor2Vec\n",
    "kor2vec = Kor2Vec.load(\"embedding_model\")\n",
    "\n",
    "kor2vec.embedding(\"옛날옛날에 커다란 호랑이가 살고 있었어요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc36c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나무꾼 -혼인: 0.1315\n",
      "신데렐라 -혼인: 0.0167\n"
     ]
    }
   ],
   "source": [
    "#cosine similiarity\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "\n",
    "male_keyword = \"나무꾼\"\n",
    "female_keyword = \"신데렐라\"\n",
    "search_keyword = \"-\"+\"혼인\"\n",
    "\n",
    "output = [cos(kor2vec.embedding(male_keyword), kor2vec.embedding(search_keyword)), cos(kor2vec.embedding(female_keyword), kor2vec.embedding(search_keyword))]\n",
    "\n",
    "male_similarity = str(str(output[0]).split('[')[1]).split(']')[0]\n",
    "female_similarity = str(str(output[1]).split('[')[1]).split(']')[0]\n",
    "\n",
    "print(male_keyword, search_keyword + ':', float(male_similarity))\n",
    "print(female_keyword, search_keyword + ':', float(female_similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a3f34",
   "metadata": {},
   "source": [
    "# 3. Define gender direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d4f0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6b2839a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPCA(a,b,num_components):\n",
    "    matrix = []\n",
    "    center = (kor2vec.embedding(a) + kor2vec.embedding(b))/2\n",
    "\n",
    "    matrix.append((kor2vec.embedding(a) - center).detach().numpy())\n",
    "    matrix.append((kor2vec.embedding(b) - center).detach().numpy())\n",
    "    matrix = np.array(matrix).reshape(2,128)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data_rescaled = scaler.fit_transform(matrix)\n",
    "    \n",
    "    pca = PCA(n_components = num_components)\n",
    "    pca = pca.fit_transform(data_rescaled)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "436c9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.024938 ],\n",
       "       [-5.0249324]], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_direction = doPCA('아빠','엄마',0.99)\n",
    "new_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0cf3db52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_direction = new_direction/ np.linalg.norm(new_direction, axis=1)[:, np.newaxis]\n",
    "norm_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(self, word1, word2):\n",
    "        v = self.vecs[self.index[word1]] - self.vecs[self.index[word2]]\n",
    "        return v/np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad837fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted([w for w in model.vocab], key=lambda w: model.vocab[w].index)\n",
    "vecs = [model[w] for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dbbf082e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordCharVocab' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15540\\515156654.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkor2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkor2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'WordCharVocab' object is not iterable"
     ]
    }
   ],
   "source": [
    "words = sorted([w for w in kor2vec.vocab], key=lambda w: kor2vec.vocab[w].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7164548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(self, word1, word2):\n",
    "        v = self.vecs[self.index[word1]] - self.vecs[self.index[word2]]\n",
    "        return v/np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b58bc8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.04878752,  0.01974712,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.07853492,\n",
       "         0.        ,  0.        ,  0.08417387, -0.16987786,  0.        ,\n",
       "         0.0554847 , -0.03808837,  0.        ,  0.        , -0.18545742,\n",
       "        -0.01373033, -0.08824214,  0.00779419,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.00864821,  0.        ,  0.        ,\n",
       "         0.        , -0.07741772, -0.0477547 ,  0.        ,  0.26623616,\n",
       "         0.11537194, -0.09130674, -0.04960033,  0.01190929, -0.06102362,\n",
       "        -0.06741846,  0.03971662, -0.02090386,  0.        ,  0.        ,\n",
       "         0.        , -0.1211992 , -0.00250281,  0.00821899,  0.08653627,\n",
       "        -0.00829001, -0.09112462,  0.05969181,  0.        ,  0.11385895,\n",
       "         0.        ,  0.02652791,  0.10450457,  0.        , -0.02511589,\n",
       "         0.11587538,  0.        , -0.17142195,  0.10516644,  0.18741913,\n",
       "         0.01184638, -0.01188518,  0.069377  ,  0.0240698 , -0.07923811,\n",
       "         0.00898017, -0.03532051,  0.00822801,  0.06957333, -0.12055543,\n",
       "         0.04560633,  0.0512903 , -0.06758367,  0.0130929 ,  0.01731354,\n",
       "        -0.05191204,  0.13458097,  0.05370057,  0.00244187,  0.00938645,\n",
       "        -0.21490681,  0.02235738,  0.13744558,  0.13050972,  0.08571202,\n",
       "        -0.11089679,  0.27848008, -0.13826628, -0.09218517,  0.06143539,\n",
       "        -0.06097367, -0.12222023, -0.08617799, -0.2048804 ,  0.01626639,\n",
       "        -0.07282957,  0.00081166,  0.19438297, -0.11918781, -0.04324406,\n",
       "        -0.02815994, -0.05210231, -0.08494941,  0.08889052,  0.08988793,\n",
       "        -0.11766792,  0.0033723 , -0.11613253,  0.20373552,  0.05605404,\n",
       "        -0.03508638, -0.08431527,  0.04302581,  0.1281587 , -0.01439396,\n",
       "         0.15789235,  0.03684042,  0.05643096, -0.11404736,  0.04509521,\n",
       "        -0.14285538, -0.18088932,  0.13374189]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = kor2vec.embedding('아빠').detach().numpy() - kor2vec.embedding('엄마').detach().numpy()\n",
    "v/np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "04ef5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_directions(self, directions): #directions better be orthogonal\n",
    "        self.desc += \", removed\"\n",
    "        for direction in directions:\n",
    "            self.desc += \" \"\n",
    "            if type(direction) is np.ndarray:\n",
    "                v = direction / np.linalg.norm(direction)\n",
    "                self.desc += \"vector \"\n",
    "            else:\n",
    "                w1, w2 = direction\n",
    "                v = self.diff(w1, w2)\n",
    "                self.desc += w1 + \"-\" + w2\n",
    "            self.vecs = self.vecs - self.vecs.dot(v)[:, np.newaxis].dot(v[np.newaxis, :])\n",
    "        self.normalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
