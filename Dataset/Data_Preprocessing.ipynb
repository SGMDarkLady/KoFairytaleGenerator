{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 92,
   "id": "02cee425",
=======
   "execution_count": null,
   "id": "02cee425",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31mc:\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:2202: FutureWarning: Supporting extra quotes around strings is deprecated in traitlets 5.0. You can use 'hmac-sha256' instead of '\"hmac-sha256\"' if you require traitlets >=5.\n",
      "\u001b[1;31m  warn(\n",
      "\u001b[1;31mc:\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:2157: FutureWarning: Supporting extra quotes around Bytes is deprecated in traitlets 5.0. Use '41fa80ec-1e9d-4f4d-9351-90667b18a016' instead of 'b\"41fa80ec-1e9d-4f4d-9351-90667b18a016\"'.\n",
      "\u001b[1;31m  warn(\n",
      "\u001b[1;31mBad file descriptor (bundled\\zeromq\\src\\epoll.cpp:100). \n",
      "자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3216058",
   "metadata": {},
   "source": [
    "# 1. Sentiment Analysis로 부정적 내용 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d08b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/sample_data/DATA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/content/sample_data/DATA/'\n",
    "print('파일 크기: ')\n",
    "for file in os.listdir(DATA_PATH):\n",
    "  if 'txt' in file:\n",
    "    print(file.ljust(30)+str(round(os.path.getsize(DATA_PATH+ file) / 100000,2))+'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09680314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레인 파일 불러오기\n",
    "train_data = pd.read_csv(DATA_PATH + 'ratings_train.txt',header = 0, delimiter = '\\t', quoting=3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 전체길이 확인\n",
    "train_length = train_data['document'].astype(str).apply(len)\n",
    "train_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c722fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 아닌 데이터 모두 제거\n",
    "train_review = [review for review in train_data['document'] if type(review) is str]\n",
    "train_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 1, 부정 0\n",
    "print('긍정 리뷰 갯수: {}'.format(train_data['label'].value_counts()[1]))\n",
    "print('부정 리뷰 갯수: {}'.format(train_data['label'].value_counts()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe222e3",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60441a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_PATH = '/content/sample_data/DATA/'\n",
    "train_data = pd.read_csv(DATA_PATH+'ratings_train.txt', header = 0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906bae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "  #함수인자설명\n",
    "  # review: 전처리할 텍스트\n",
    "  # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\n",
    "  # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "  # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "  # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "  review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "  \n",
    "  #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "  word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "  if remove_stopwords:\n",
    "    #3. 불용어 제거(선택)\n",
    "    word_review = [token for token in word_review if not token in stop_words]\n",
    "  return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트 전처리\n",
    "stop_words = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한']\n",
    "okt = Okt()\n",
    "clean_train_review = []\n",
    "\n",
    "for review in train_data['document']:\n",
    "  # 리뷰가 문자열인 경우만 전처리 진행\n",
    "  if type(review) == str:\n",
    "    clean_train_review.append(preprocessing(review,okt,remove_stopwords=True,stop_words= stop_words))\n",
    "  else:\n",
    "    clean_train_review.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "\n",
    "clean_train_review[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 리뷰도 동일하게 전처리\n",
    "test_data = pd.read_csv(DATA_PATH + 'ratings_test.txt', header = 0, delimiter='\\t', quoting=3)\n",
    "\n",
    "clean_test_review = []\n",
    "for review in test_data['document']:\n",
    "  if type(review) == str:\n",
    "    clean_test_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "  else:\n",
    "    clean_test_review.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 벡터 변환 후 일정 길이 넘어가거나 모자라는 리뷰 패딩처리\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
    "\n",
    "word_vocab = tokenizer.word_index #단어사전형태\n",
    "MAX_SEQUENCE_LENGTH = 8 #문장 최대 길이\n",
    "\n",
    "#학습 데이터\n",
    "train_inputs = pad_sequences(train_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "#학습 데이터 라벨 벡터화\n",
    "train_labels = np.array(train_data['label'])\n",
    "\n",
    "#평가 데이터 \n",
    "test_inputs = pad_sequences(test_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "#평가 데이터 라벨 벡터화\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PATH  = '/content/sample_data/'\n",
    "DATA_PATH = 'CLEAN_DATA/'\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "data_configs={}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) + 1\n",
    "\n",
    "#전처리한 데이터들 파일로저장\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DEFAULT_PATH + DATA_PATH):\n",
    "  os.makedirs(DEFAULT_PATH+DATA_PATH)\n",
    "\n",
    "#전처리 학습데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\n",
    "#전처리 테스트데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\n",
    "\n",
    "#데이터 사전 json으로 저장\n",
    "json.dump(data_configs,open(DEFAULT_PATH + DATA_PATH + DATA_CONFIGS,'w'),ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4177892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 데이터 불러오기\n",
    "DATA_PATH = '/content/sample_data/CLEAN_DATA/'\n",
    "DATA_OUT = '/content/sample_data/DATA_OUT/'\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "LABEL_TRAIN_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "train_input = np.load(open(DATA_PATH + INPUT_TRAIN_DATA,'rb'))\n",
    "train_input = pad_sequences(train_input,maxlen=train_input.shape[1])\n",
    "train_label = np.load(open(DATA_PATH + LABEL_TRAIN_DATA,'rb'))\n",
    "prepro_configs = json.load(open(DATA_PATH+DATA_CONFIGS,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= 'cnn_classifier_kr'\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 10\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs={'model_name': model_name, 'vocab_size':prepro_configs['vocab_size'],'embbeding_size':128, 'num_filters':100,'dropout_rate':0.5, 'hidden_dimension':250,'output_dimension':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, **kargs):\n",
    "    super(CNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "    self.embedding = layers.Embedding(input_dim=kargs['vocab_size'], output_dim=kargs['embbeding_size'])\n",
    "    self.conv_list = [layers.Conv1D(filters=kargs['num_filters'], kernel_size=kernel_size, padding='valid',activation = tf.keras.activations.relu,\n",
    "                                    kernel_constraint = tf.keras.constraints.MaxNorm(max_value=3)) for kernel_size in [3,4,5]]\n",
    "    self.pooling = layers.GlobalMaxPooling1D()\n",
    "    self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "    self.fc1 = layers.Dense(units=kargs['hidden_dimension'],\n",
    "                            activation = tf.keras.activations.relu,\n",
    "                            kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    self.fc2 = layers.Dense(units=kargs['output_dimension'],\n",
    "                            activation=tf.keras.activations.sigmoid,\n",
    "                            kernel_constraint= tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    \n",
    "\n",
    "  def call(self,x):\n",
    "    x = self.embedding(x)\n",
    "    x = self.dropout(x)\n",
    "    x = tf.concat([self.pooling(conv(x)) for conv in self.conv_list], axis = 1)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
    "\n",
    "#검증 정확도를 통한 EarlyStopping 기능 및 모델 저장 방식 지정\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
    "checkpoint_path = DATA_OUT + model_name +'\\weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "  print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "  print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor = 'val_accuracy', verbose=1, save_best_only = True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs = NUM_EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "# 모델 저장하기\n",
    "save_model(model,'/content/sample_data/my_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84804d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 zip파일로 저장\n",
    "!zip -r /content/sample_data/my_models.zip /content/sample_data/my_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 zip파일 다운로드\n",
    "from google.colab import files\n",
    "files.download('/content/sample_data/my_models.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e28f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "test_input = np.load(open(DATA_PATH+INPUT_TEST_DATA,'rb'))\n",
    "test_input = pad_sequences(test_input,maxlen=test_input.shape[1])\n",
    "test_label_data = np.load(open(DATA_PATH + LABEL_TEST_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/content/sample_data/DATA_OUT/cnn_classifier_kr\\weights.h5')\n",
    "model.evaluate(test_input, test_label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding =\"UTF-8\") as f:\n",
    "        fr = f.read()\n",
    "    return fr\n",
    "\n",
    "def read_csv(file_path):\n",
    "    fr = pd.read_csv(file_path, encoding = \"windows-1252\")\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 여러개 시트를 취득\n",
    "stories = pd.read_excel('/content/sample_data/DATA/tmp_dataset.xlsx')\n",
    "stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac752260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "negative_story = []\n",
    "\n",
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()\n",
    "\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "prepro_configs = json.load(open('/content/sample_data/CLEAN_DATA/'+DATA_CONFIGS,'r'))\n",
    "prepro_configs['vocab'] = word_vocab\n",
    "\n",
    "tokenizer.fit_on_texts(word_vocab)\n",
    "\n",
    "MAX_LENGTH = 1000 #문장최대길이\n",
    "\n",
    "#sentence = input('감성분석할 문장을 입력해 주세요.: ')\n",
    "#print(sentence)\n",
    "#sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "stopwords = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'] # 불용어 추가할 것이 있으면 이곳에 추가\n",
    "#sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "#sentence = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "#vector  = tokenizer.texts_to_sequences(sentence)\n",
    "#pad_new = pad_sequences(vector, maxlen = MAX_LENGTH) # 패딩\n",
    "#print('변환된 문자 결과값: ',pad_new)\n",
    "model.load_weights('/content/sample_data/DATA_OUT/cnn_classifier_kr\\weights.h5') #모델 불러오기\n",
    "\n",
    "for i in range(len(stories)):\n",
    "  sentence = stories[0][i]\n",
    "  sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "  sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "  sentence = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "  vector  = tokenizer.texts_to_sequences(sentence)\n",
    "  pad_new = pad_sequences(vector, maxlen = MAX_LENGTH) # 패딩\n",
    "  predictions = model.predict(pad_new)\n",
    "  predictions = float(predictions.squeeze(-1)[1])\n",
    "  #print(predictions)\n",
    "  if(predictions <= 0.2):\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - predictions) * 100))\n",
    "    print(sentence)\n",
    "    negative_story.append([i,stories[0][i],1-predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd352ff",
   "metadata": {},
   "source": [
    "# 2. Unsmile로 혐오 표현 데이터셋 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c4984",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31mc:\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:2202: FutureWarning: Supporting extra quotes around strings is deprecated in traitlets 5.0. You can use 'hmac-sha256' instead of '\"hmac-sha256\"' if you require traitlets >=5.\n",
      "\u001b[1;31m  warn(\n",
      "\u001b[1;31mc:\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:2157: FutureWarning: Supporting extra quotes around Bytes is deprecated in traitlets 5.0. Use '41fa80ec-1e9d-4f4d-9351-90667b18a016' instead of 'b\"41fa80ec-1e9d-4f4d-9351-90667b18a016\"'.\n",
      "\u001b[1;31m  warn(\n",
      "\u001b[1;31mBad file descriptor (bundled\\zeromq\\src\\epoll.cpp:100). \n",
      "자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2927ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n",
    "torch.cuda.is_available()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda62061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866cbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding =\"UTF-8\") as f:\n",
    "        fr = f.read()\n",
    "    return fr\n",
    "\n",
    "def read_csv(file_path):\n",
    "    fr = pd.read_csv(file_path, encoding = \"utf-8\")\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "tales = []\n",
    "hansam = read_csv(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[csv]hanguelsam_dataset.csv\")\n",
    "for i in range(len(hansam['동화'])):\n",
    "    tales.append(hansam['동화'][i])\n",
    "\n",
    "ollybolly = read_csv(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[csv]ollybolly_story_dataset.csv\")\n",
    "for i in range(len(ollybolly['동화'])):\n",
    "    tales.append(ollybolly['동화'][i])\n",
    "\n",
    "bluehouse1 = read_csv(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[csv]bluehouse1.csv\")\n",
    "for i in range(len(bluehouse1['동화'])):\n",
    "    tales.append(bluehouse1['동화'][i])\n",
    "\n",
    "bluehouse2 = read_csv(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[csv]bluehouse2.csv\")\n",
    "for i in range(len(bluehouse2['동화'])):\n",
    "    tales.append(bluehouse2['동화'][i])\n",
    "\n",
    "bang = read_csv(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[csv]bang_story_dataset.csv\")\n",
    "for i in range(len(bang['동화'])):\n",
    "    tales.append(bang['동화'][i])\n",
    "\n",
    "donghwa = read_txt(\"C:\\\\Users\\\\user/SGM_AI/darklady/dataset/[txt]donghwa_korean.txt\").split('\\n')\n",
    "for i in range(len(donghwa)):\n",
    "    tales.append(donghwa[i])\n",
    "    \n",
    "print(len(hansam['동화']))\n",
    "print(len(ollybolly['동화']))\n",
    "print(len(bluehouse1['동화']))\n",
    "print(len(bluehouse2['동화']))\n",
    "print(len(bang['동화']))\n",
    "print(len(donghwa))\n",
    "len(tales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataset = pd.DataFrame(tales)\n",
    "tmp_dataset.to_csv('tmp_dataset.csv')\n",
    "tmp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = tmp_dataset\n",
    "stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ab8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets==1.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60becf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smilegate Unsmile dataset\n",
    "#https://github.com/smilegate-ai/korean_unsmile_dataset\n",
    "#https://arxiv.org/ftp/arxiv/papers/2204/2204.03262.pdf\n",
    "#https://colab.research.google.com/drive/1NKYYVSex__vde-lnYCmsRmyHjJhV6cKt?usp=sharing#scrollTo=D75_HqO3V7ZT\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('smilegate-ai/kor_unsmile')\n",
    "print(datasets)\n",
    "\n",
    "datasets[\"train\"][0]\n",
    "dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febe432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'monologg/kobigbird-bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011cfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    tokenized_examples = tokenizer(str(examples[\"문장\"]))\n",
    "    tokenized_examples['labels'] = torch.tensor(examples[\"labels\"], dtype=torch.float)\n",
    "    # multi label classification 학습을 위해선 label이 float 형태로 변형되어야 합니다.\n",
    "    # huggingface datasets 최신 버전에는 'map' 함수에 버그가 있어서 변형이 올바르게 되지 않습니다.\n",
    "    \n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad16da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask', 'token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27379df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmile_labels = [\"여성/가족\",\"남성\",\"성소수자\",\"인종/국적\",\"연령\",\"지역\",\"종교\",\"기타 혐오\",\"악플/욕설\",\"clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(unsmile_labels) # Label 갯수\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels, \n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.config.id2label = {i: label for i, label in zip(range(num_labels), unsmile_labels)}\n",
    "model.config.label2id = {label: i for i, label in zip(range(num_labels), unsmile_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ecf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###3. Model training\n",
    "from sklearn.metrics import label_ranking_average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffdd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(x):\n",
    "    return {\n",
    "        'lrap': label_ranking_average_precision_score(x.label_ids, x.predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae402010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cac1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"unsmile_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='lrap',\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"valid\"], \n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66176ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d10e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b81864",
   "metadata": {},
   "outputs": [],
   "source": [
    "###4. Model test\n",
    "#(if you use model after your own fine tuning)\n",
    "# from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(if you use original fine-tuned model)\n",
    "from transformers import TextClassificationPipeline, BertForSequenceClassification, AutoTokenizer,pipeline\n",
    "\n",
    "model_name = 'smilegate-ai/kor_unsmile'\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(task='sentiment-analysis',model=model_name,tokenizer=tokenizer)\n",
    "\n",
    "pipe = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0,     # cpu: -1, gpu: gpu number\n",
    "    return_all_scores=True,\n",
    "    function_to_apply='sigmoid'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "    l_total = []\n",
    "    l_partial = []\n",
    "    if len(text1.split())//40>0:\n",
    "        n = len(text1.split())//40\n",
    "    else:\n",
    "        n=1\n",
    "    for w in range(n):\n",
    "        if w==0:\n",
    "            l_partial = text1.split()[:80]\n",
    "            l_total.append(\" \".join(l_partial))\n",
    "        else:\n",
    "            l_partial = text1.split()[w*40:w*40+80]\n",
    "            l_total.append(\" \".join(l_partial))\n",
    "    return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stories=[]\n",
    "for i in range(len(stories)):\n",
    "    split_story = get_split(str(stories[0][i]))\n",
    "    split_stories.append(split_story)\n",
    "split_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbbd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = classifier(str(split_stories[0][0]))\n",
    "print(split_stories[0][0])\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa375285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = classifier(str(split_stories[0][1]))\n",
    "print(split_stories[0][1])\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(str(stories[0][300]))\n",
    "#print(len(stories))\n",
    "\n",
    "#stories[0][1]\n",
    "#for result in pipe( \"4월의 친구 화창한 4월의 봄이에요. 할아버지와 은교가 함께 나들이를 가요. 할아버지, 동물원 가는 거예요? 아니, 할아버지 친구 만나러 가는 길이란다. 칫, 재미없어, 난 동물원이 좋은데.. 두 사람이 도착한 곳은 서울 수유동에 있는 4.19 국립묘지예요. 연분홍 진달래가 활짝 피어있었죠. 이곳에 묻힌 분들은 옳은 일에 목숨을 받친 용기있는 사람들이었답니다. 앞서가던 할아버지가 어느 묘소 앞에 멈췄어요. 비석에는 까까머리 학생의 흑백사진이 붙혀 있었죠. 할아버지 눈가에 눈물이 맺혔어요. 어, 할아버지 왜 우세요? 어리둥절해진 민규가 물었죠. 친구가 보고 싶어서 그러지. 이렇게 어린 사람이 어떻게 할아버지 친구예요? 고등학교 때 단짝친구였단다. 정말요? 그럼 언제 돌아가신 거예요? 할아버지의 눈시울이 붉어졌어요. 옛날옛날에 먼저 하늘 나라로 갔단다. 오늘은 내가 친구를 잃어버린지 55년이 되는 날이야. 그때는 모두 너무나 가난했지. 아침 밥도 못먹고, 학교에 가서 점심 시간이 되면 수돗가에 가서 물로 배를 채우곤했단다. 네? 할아버지, 왜 먹을 게 없어요? 전쟁이 끝난지 얼마 되지 않았을테니까. 전쟁은 많은 사람들의 목숨을 빼앗고, 집과 일터를 앗아갔단다. 나라를 다시 세우는 일에 앞장서야 했던 사람이 대통령이야. 대통령은 국민을 대신해서 나라 살림을 잘 꾸려가라고 국민들이 뽑아준 사람이었으니까. 하지만 그 시절 대통령은 국민들의 뜻을 잘 받들지 않았단다. 그때 대통령이 누군데요? 이승만이지, 우리나라의 최초의 대통령이었단다. 국민의 뜻에 따라야 할 중요한 일들을 대통령과 높은 관직에 있던 사람들은 자기들 마음대로 결정해 버렸어. 그래서 사람들은 점점 더 살기 힘들어졌지. 나라를 이끄는 사람들이 자기 욕심만 채우려 했으니까. 나라의 주인은 국민인데 대통령이 주인 행세를 한 거야. 그래서 국민들도 차츰 대통령의 잘못을 알게 되었어. 그런데도 이승만은 계속 대통령을 하고 싶어했지. 결국에 3번이나 대통령이 되었단다. 우와, 그럼 굉장히 오래동안 대통령을 했겠네요? 그랬었지. 1960년에 네 번째 대통령 선거가 다가왔어. 모두들 이번에는 다른 대통령이 나올거라 기대했단다. 국민들에게 인심을 잃은 이승만은 이번에는 깡패를 동원해서 사람들을 협박했어. 그리고 대통령을 뽑는 날이 되었지. 그런데 이상한 일이 벌어졌어. 이승만이 또 대통령이 된 거야. 알고보니 이승만을 찍은 가짜 투표용지를 진짜 투표 용지와 바꿔치기 한거였지. 그 때 국민들은 더는 참을 수가 없었어. 선거는 국민에게 주어진 소중한 권리인데 대통령이 자기 욕심을 채우기 위해 그 권리마저 짓밟고 말았던 거야. 그날 경상남도 마산에 수천명이 모였지. 사람들은 선거를 다시 하라고 외쳤어. 그리고 함성은 점점 커져갔어. 그런게 갑자기 경찰이 총을 쏘아대는거야. 많은 사람들이 다치거나 목숨을 잃고 말았지. 그리고 한달쯤 지나 엄청난 소식이 전해졌어. 바다에서 한 학생의 시체가 발견된 거야. 경찰이 사람이 죽은 걸 숨기려고 바다에 던진 거였어. 할아버지의 목소리는 점점 울분으로 가득찼어요. 한 고등학생의 처참한 죽음은 온 국민의 마음을 끓어오르게 만들었답니다. 그리고 4월 19일이 되었어요. 전국의 온 거리가 성난 사람들로 가득찼죠. 교복을 입은 할아버지도 친구와 함께 목이 터져라 외쳤습니다. 이승만 물러가라! 깡패정치 물러가라! 할아버지와 친구는 손을 꼭잡고 계속 앞으로 나갔습니다. 할아버지와 친구에게 총알이 쏟아졌어요. 할아버지는 총에 맞은 다리를 끌며 일어났죠. 하지만 쓰러진 친구는 다시 일어나지 못했습니다. 결국 이승만은 국민들에게 사과하고 대통령직에서 물러났어요.  국민을 무시하고 주인 행세를 한 대통령을 국민의 힘으로 몰아낸 이 사건이 바로 '4.19 혁명'이랍니다. 나라는 한 사람이 자기 욕심대로 다스려서는 안 된단다. 국민의 뜻을 받들어 나라를 다스리는 것, 그게 바로 '민주주의'란다. 4.19혁명을 겪으면서 많은 사람들은 민주주의가 얼마나 소중한 것인지 깨닫게 되었답니다. 이 일이 있은 후에도 총, 칼을 앞세워서 국민들을 위협하고 자기 마음대로 나라를 다스리려는 사람들이 늘 나타났어. 그때마다 국민들은 그런 사람들을 몰아내기 위해 노력했지. 그럼 또 많은 사람들이 다치고 죽었어요? 그렇단다, 우리나라의 민주주의는 쉽게 만들어진 것이 아니야. 많은 사람들의 용기와 희생으로 이루어졌단다. 집으로 돌아갈 시간이 되었어요. 민규는 할아버지의 지팡이를 챙겨 드렸죠. 할아버지, 다리 많이 아프셨죠? 이제 제가 많이 도와드릴게요. 허허~우리 손자가 금방 어른이 되었네! 할아버지는 민규의 머리를 쓰다듬어 주셨어요. 할아버지는 진달래 꽃을 보면 자꾸 친구 생각이 난답니다. 오늘 할아버지의 친구 이야기를 들으며 민규는 마음속 깊이 4월의 진달래꽃을 심었답니다. 학생과 시민의 희생으로 피운 꽃 민주주의 소중하고 감사한 마음으로 앞으로도 잘 지켜나가야 할 것입니다.\"):\n",
    "#    print(result)\n",
    "classified_df = []\n",
    "list=[]\n",
    "for i in range(len(stories)):\n",
    "    list=[]\n",
    "    for j in range(len(split_stories[i])):\n",
    "        for sentiment in pipe(str(split_stories[i][j])):\n",
    "            list.append(sentiment)       \n",
    "    classified_df.append(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb20638",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3216058",
   "metadata": {},
   "source": [
    "# 1. Sentiment Analysis로 부정적 내용 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a9675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd352ff",
   "metadata": {},
   "source": [
    "# 2. Unsmile로 혐오 표현 데이터셋 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c4984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b53e76d",
   "metadata": {},
   "source": [
    "# 3. Gender Swapping Data Augmentation(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "23f3e764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1314 entries, 0 to 1313\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1314 non-null   int64 \n",
      " 1   동화          1275 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 20.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/dataset.csv', encoding='UTF-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb846de",
   "metadata": {},
   "source": [
    "## 3-1) 익명화\n",
    "동화 데이터에 등장하는 등장인물들의 이름을 익명화합니다. 이름에 의한 성별 고정관념을 없애는 과정입니다.\n",
    "<br>각 인물별로 번호를 메겨 E(번호) 형태의 토큰으로 대체합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aff96e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       다다\n",
       "1      방정환\n",
       "2      손기정\n",
       "3       선미\n",
       "4      반쪽이\n",
       "      ... \n",
       "227    바오밥\n",
       "228    마룰라\n",
       "229    와르다\n",
       "230     롤리\n",
       "231     월터\n",
       "Name: 인물, Length: 232, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list = pd.read_csv('GenderSwapping/character.txt')['인물']\n",
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3001c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(text, name_list):\n",
    "    for i in range(len(name_list)):\n",
    "        #new_name = '인물' + str(i)\n",
    "        text = text.replace(name_list[i], '<인물' + str(i) +'>')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "065bd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymized_data = []\n",
    "for i in range(len(df['동화'])):\n",
    "    story = str(df['동화'][i])\n",
    "    text = anonymize(story, name_list)\n",
    "    anonymized_data.append(text)\n",
    "    \n",
    "data = {'동화':anonymized_data}\n",
    "anonymized_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30127eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터: 1314 anonymized 데이터: 1314\n",
      "원본 데이터 \"방정환\" 등장 수: 4 [1, 2, 565, 809]\n",
      "anonymized 데이터 \"방정환\" 등장 수: 4 [1, 2, 565, 809]\n"
     ]
    }
   ],
   "source": [
    "#제대로 익명화되었는지 확인하기\n",
    "print('원본 데이터:', len(df['동화']), 'anonymized 데이터:', len(anonymized_df))\n",
    "print(\n",
    "    '원본 데이터 \"방정환\" 등장 수:', \n",
    "      len(df[df['동화'].str.contains('방정환', na=False)]),\n",
    "      df.index[df['동화'].str.contains('방정환', na=False)].tolist()\n",
    ")\n",
    "print(\n",
    "    'anonymized 데이터 \"방정환\" 등장 수:',\n",
    "      len(anonymized_df.query('동화.str.contains(\"<인물1>\")')),\n",
    "     anonymized_df.index[anonymized_df['동화'].str.contains('<인물1>', na=False)].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00f8ff",
   "metadata": {},
   "source": [
    "## 3-2) 여성어/남성어 바꾸기 \n",
    "1. 엄마/아빠, 할머니/할아버지, 공주/왕자 등 단어에 성별을 유추할 수 있는 단어들을 sawpping합니다. 이를 통해 주어 뒤에 서술되는 요소가 주어의 성별에 영향을 받지 않도록 만듭니다.\n",
    "2. '여배우(=배우)', '하녀(=하인)'처럼 stem이 되는 단어가 보편적 기준으로서 남성을 지칭하고, 여성을 지칭하기 위해 단어의 앞이나 뒤에 '-여'를 붙인 단어들을 stem이 되는 단어로 바꿉니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863710bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_list 정의\n",
    "female_word_list = [\n",
    "    '엄마', '할머니', '여왕', '공주', '그녀', '여신', '하녀', '여학생', '의붓어머니', '계모', '마녀',\n",
    "    '여자아이', '간호사', '여의사','그녀', '신부', '과부', '미망인', '소녀', '모성애', '아내', '집사람', '손녀',\n",
    "    '처녀', '여자친구', '딸', '언니', '누나','새언니', '숙녀', '여성'\n",
    "]\n",
    "\n",
    "male_word_list = [\n",
    "    '아빠', '할아버지', '왕', '왕자', '그', '신', '하인', '학생', '의붓아버지', '계부', '마법사',\n",
    "    '남자아이', '의사','의사', '그', '신랑', '홀아비', '홀아비', '소년', '부성애', '남편', '바깥사람', '손자',\n",
    "    '총각', '남자친구', '아들', '오빠', '형','새오빠', '신사', '남성'\n",
    "]\n",
    "\n",
    "조사_list = ['께', '에게', '한테', '더러', '에서','의',\n",
    "          '에게서', '한테서', '와', '하고', '처럼', '같이', '보다',\n",
    "          '만큼', '도']\n",
    "\n",
    "#은/는, 이/가는 수작업으로 붙인다.\n",
    "additional_female_word_list = [\n",
    "    '엄마는', '엄마가', '할머니는', '할머니가', '여왕이', '여왕은', '공주가', '공주는', '그녀가', '그녀는', '여신이', '여신은'\n",
    "    '하녀가', '하녀는', '여학생은', '여학생이', '의붓어머니가', '의붓어머니는', '계모가', '계모는', '마녀가', '마녀는',\n",
    "    '여자아이가', '여자아이는', '간호사가', '간호사는', '여의사가', '여의사는','그녀는', '그녀가', '신부는', '신부가', '과부가', '과부는', '미망인은','미망인이',\n",
    "    '소녀가', '소녀는','모성애가', '모성애는', '아내는', '아내가', '집사람이', '집사람은', '손녀는', '손녀가', '처녀가', '처녀는',\n",
    "    '여자친구가', '여자친구는','딸은', '딸이', '언니가', '언니는', '누나가', '누나는', '새언니가', '새언니는', '숙녀가', '숙녀는',\n",
    "    '여성이', '여성은']\n",
    "\n",
    "additional_male_word_list = [\n",
    "    '아빠는', '아빠가', '할아버지는', '할아버지가', '왕이', '왕은', '왕자가', '왕자는', '그가', '그는', '신이', '신은'\n",
    "    '하인이', '하인은', '남학생은', '남학생이', '의붓아버지가', '의붓아버지는', '계부가', '계부는', '마법사가', '마법사는',\n",
    "    '남자아이가', '남자아이는', '의사가', '의사는', '의사가', '의사는', '그는', '그가', '신랑은', '신랑이', '홀아비가', '홀아비는', '홀아비는','홀아비가',\n",
    "    '소년이', '소년은','부성애가', '부성애는', '남편은', '남편이', '바깥사람이', '바깥사람은', '손자는', '손자가', '총각이', '총각은',\n",
    "    '남자친구가', '남자친구는','아들은', '아들이', '오빠가', '오빠는', '형이', '형은', '새오빠가', '새오빠는', '신사가', '신사는',\n",
    "    '남성이', '남성은']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de042a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grammer(origin_word_list, additional_list):\n",
    "    final_word = []\n",
    "    for i in range(len(origin_word_list)):\n",
    "        for n in range(len(조사_list)):\n",
    "            word = str(origin_word_list[i])+str(조사_list[n])\n",
    "            final_word.append(word)\n",
    "    for x in range(len(additional_list)):\n",
    "        final_word.append(additional_list[x])\n",
    "    return final_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6176125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_female_word_list = add_grammer(female_word_list, additional_female_word_list)\n",
    "\n",
    "final_male_word_list = add_grammer(male_word_list, additional_male_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dc82d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['엄마께', '엄마에게', '엄마한테', '엄마더러', '엄마에서', '엄마의', '엄마에게서', '엄마한테서', '엄마와', '엄마하고', '엄마처럼', '엄마같이', '엄마보다', '엄마만큼', '엄마도', '할머니께', '할머니에게', '할머니한테', '할머니더러', '할머니에서', '할머니의', '할머니에게서', '할머니한테서', '할머니와', '할머니하고', '할머니처럼', '할머니같이', '할머니보다', '할머니만큼', '할머니도', '여왕께', '여왕에게', '여왕한테', '여왕더러', '여왕에서', '여왕의', '여왕에게서', '여왕한테서', '여왕와', '여왕하고', '여왕처럼', '여왕같이', '여왕보다', '여왕만큼', '여왕도', '공주께', '공주에게', '공주한테', '공주더러', '공주에서', '공주의', '공주에게서', '공주한테서', '공주와', '공주하고', '공주처럼', '공주같이', '공주보다', '공주만큼', '공주도', '그녀께', '그녀에게', '그녀한테', '그녀더러', '그녀에서', '그녀의', '그녀에게서', '그녀한테서', '그녀와', '그녀하고', '그녀처럼', '그녀같이', '그녀보다', '그녀만큼', '그녀도', '여신께', '여신에게', '여신한테', '여신더러', '여신에서', '여신의', '여신에게서', '여신한테서', '여신와', '여신하고', '여신처럼', '여신같이', '여신보다', '여신만큼', '여신도', '하녀께', '하녀에게', '하녀한테', '하녀더러', '하녀에서', '하녀의', '하녀에게서', '하녀한테서', '하녀와', '하녀하고', '하녀처럼', '하녀같이', '하녀보다', '하녀만큼', '하녀도', '여학생께', '여학생에게', '여학생한테', '여학생더러', '여학생에서', '여학생의', '여학생에게서', '여학생한테서', '여학생와', '여학생하고', '여학생처럼', '여학생같이', '여학생보다', '여학생만큼', '여학생도', '의붓어머니께', '의붓어머니에게', '의붓어머니한테', '의붓어머니더러', '의붓어머니에서', '의붓어머니의', '의붓어머니에게서', '의붓어머니한테서', '의붓어머니와', '의붓어머니하고', '의붓어머니처럼', '의붓어머니같이', '의붓어머니보다', '의붓어머니만큼', '의붓어머니도', '계모께', '계모에게', '계모한테', '계모더러', '계모에서', '계모의', '계모에게서', '계모한테서', '계모와', '계모하고', '계모처럼', '계모같이', '계모보다', '계모만큼', '계모도', '마녀께', '마녀에게', '마녀한테', '마녀더러', '마녀에서', '마녀의', '마녀에게서', '마녀한테서', '마녀와', '마녀하고', '마녀처럼', '마녀같이', '마녀보다', '마녀만큼', '마녀도', '여자아이께', '여자아이에게', '여자아이한테', '여자아이더러', '여자아이에서', '여자아이의', '여자아이에게서', '여자아이한테서', '여자아이와', '여자아이하고', '여자아이처럼', '여자아이같이', '여자아이보다', '여자아이만큼', '여자아이도', '간호사께', '간호사에게', '간호사한테', '간호사더러', '간호사에서', '간호사의', '간호사에게서', '간호사한테서', '간호사와', '간호사하고', '간호사처럼', '간호사같이', '간호사보다', '간호사만큼', '간호사도', '여의사께', '여의사에게', '여의사한테', '여의사더러', '여의사에서', '여의사의', '여의사에게서', '여의사한테서', '여의사와', '여의사하고', '여의사처럼', '여의사같이', '여의사보다', '여의사만큼', '여의사도', '그녀께', '그녀에게', '그녀한테', '그녀더러', '그녀에서', '그녀의', '그녀에게서', '그녀한테서', '그녀와', '그녀하고', '그녀처럼', '그녀같이', '그녀보다', '그녀만큼', '그녀도', '신부께', '신부에게', '신부한테', '신부더러', '신부에서', '신부의', '신부에게서', '신부한테서', '신부와', '신부하고', '신부처럼', '신부같이', '신부보다', '신부만큼', '신부도', '과부께', '과부에게', '과부한테', '과부더러', '과부에서', '과부의', '과부에게서', '과부한테서', '과부와', '과부하고', '과부처럼', '과부같이', '과부보다', '과부만큼', '과부도', '미망인께', '미망인에게', '미망인한테', '미망인더러', '미망인에서', '미망인의', '미망인에게서', '미망인한테서', '미망인와', '미망인하고', '미망인처럼', '미망인같이', '미망인보다', '미망인만큼', '미망인도', '소녀께', '소녀에게', '소녀한테', '소녀더러', '소녀에서', '소녀의', '소녀에게서', '소녀한테서', '소녀와', '소녀하고', '소녀처럼', '소녀같이', '소녀보다', '소녀만큼', '소녀도', '모성애께', '모성애에게', '모성애한테', '모성애더러', '모성애에서', '모성애의', '모성애에게서', '모성애한테서', '모성애와', '모성애하고', '모성애처럼', '모성애같이', '모성애보다', '모성애만큼', '모성애도', '아내께', '아내에게', '아내한테', '아내더러', '아내에서', '아내의', '아내에게서', '아내한테서', '아내와', '아내하고', '아내처럼', '아내같이', '아내보다', '아내만큼', '아내도', '집사람께', '집사람에게', '집사람한테', '집사람더러', '집사람에서', '집사람의', '집사람에게서', '집사람한테서', '집사람와', '집사람하고', '집사람처럼', '집사람같이', '집사람보다', '집사람만큼', '집사람도', '손녀께', '손녀에게', '손녀한테', '손녀더러', '손녀에서', '손녀의', '손녀에게서', '손녀한테서', '손녀와', '손녀하고', '손녀처럼', '손녀같이', '손녀보다', '손녀만큼', '손녀도', '처녀께', '처녀에게', '처녀한테', '처녀더러', '처녀에서', '처녀의', '처녀에게서', '처녀한테서', '처녀와', '처녀하고', '처녀처럼', '처녀같이', '처녀보다', '처녀만큼', '처녀도', '여자친구께', '여자친구에게', '여자친구한테', '여자친구더러', '여자친구에서', '여자친구의', '여자친구에게서', '여자친구한테서', '여자친구와', '여자친구하고', '여자친구처럼', '여자친구같이', '여자친구보다', '여자친구만큼', '여자친구도', '딸께', '딸에게', '딸한테', '딸더러', '딸에서', '딸의', '딸에게서', '딸한테서', '딸와', '딸하고', '딸처럼', '딸같이', '딸보다', '딸만큼', '딸도', '언니께', '언니에게', '언니한테', '언니더러', '언니에서', '언니의', '언니에게서', '언니한테서', '언니와', '언니하고', '언니처럼', '언니같이', '언니보다', '언니만큼', '언니도', '누나께', '누나에게', '누나한테', '누나더러', '누나에서', '누나의', '누나에게서', '누나한테서', '누나와', '누나하고', '누나처럼', '누나같이', '누나보다', '누나만큼', '누나도', '새언니께', '새언니에게', '새언니한테', '새언니더러', '새언니에서', '새언니의', '새언니에게서', '새언니한테서', '새언니와', '새언니하고', '새언니처럼', '새언니같이', '새언니보다', '새언니만큼', '새언니도', '숙녀께', '숙녀에게', '숙녀한테', '숙녀더러', '숙녀에서', '숙녀의', '숙녀에게서', '숙녀한테서', '숙녀와', '숙녀하고', '숙녀처럼', '숙녀같이', '숙녀보다', '숙녀만큼', '숙녀도', '여성께', '여성에게', '여성한테', '여성더러', '여성에서', '여성의', '여성에게서', '여성한테서', '여성와', '여성하고', '여성처럼', '여성같이', '여성보다', '여성만큼', '여성도', '엄마는', '엄마가', '할머니는', '할머니가', '여왕이', '여왕은', '공주가', '공주는', '그녀가', '그녀는', '여신이', '여신은하녀가', '하녀는', '여학생은', '여학생이', '의붓어머니가', '의붓어머니는', '계모가', '계모는', '마녀가', '마녀는', '여자아이가', '여자아이는', '간호사가', '간호사는', '여의사가', '여의사는', '그녀는', '그녀가', '신부는', '신부가', '과부가', '과부는', '미망인은', '미망인이', '소녀가', '소녀는', '모성애가', '모성애는', '아내는', '아내가', '집사람이', '집사람은', '손녀는', '손녀가', '처녀가', '처녀는', '여자친구가', '여자친구는', '딸은', '딸이', '언니가', '언니는', '누나가', '누나는', '새언니가', '새언니는', '숙녀가', '숙녀는', '여성이', '여성은']\n"
     ]
    }
   ],
   "source": [
    "print(final_female_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "504c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, origin_word_list):\n",
    "    for i in range(len(origin_word_list)):\n",
    "        text = text.replace(origin_word_list[i], '*'+origin_word_list[i])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c918016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_swapping(text, origin_word_list, swapped_word_list):\n",
    "    for i in range(len(origin_word_list)):\n",
    "        text = text.replace('*'+origin_word_list[i], swapped_word_list[i])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ac43e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_data = []\n",
    "for i in range(len(df)):\n",
    "    story = str(anonymized_df['동화'][i])\n",
    "    f_to_m = preprocessing(story, final_female_word_list)\n",
    "    m_to_f = preprocessing(f_to_m, final_male_word_list)\n",
    "    f_to_m_swapped = gender_swapping(m_to_f, final_female_word_list, final_male_word_list)\n",
    "    m_to_f_swapped = gender_swapping(f_to_m_swapped, final_male_word_list, final_female_word_list)\n",
    "    swapped_data.append(m_to_f_swapped)\n",
    "    \n",
    "data = {'동화':swapped_data}\n",
    "gender_swapped_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98ebfffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터: 1314 swapped 데이터: 1314\n",
      "원본 데이터 할머니 단어 수: 109\n",
      "원본 데이터 할아버지 단어 수: 100\n",
      "swapped 데이터 할머니 단어 수: 100\n",
      "swapped 데이터 할아버지 단어 수: 109\n"
     ]
    }
   ],
   "source": [
    "#제대로 swapped되었는지 확인\n",
    "print('원본 데이터:', len(df['동화']), 'swapped 데이터:', len(gender_swapped_df))\n",
    "print('원본 데이터 할머니 단어 수:', len(df[df['동화'].str.contains('할머니가', na=False)]))\n",
    "print('원본 데이터 할아버지 단어 수:', len(df[df['동화'].str.contains('할아버지가', na=False)]))\n",
    "print('swapped 데이터 할머니 단어 수:', len(gender_swapped_df.query('동화.str.contains(\"할머니가\")')))\n",
    "print('swapped 데이터 할아버지 단어 수:', len(gender_swapped_df.query('동화.str.contains(\"할아버지가\")')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ece6b9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 우리 친구들은 미술이 뭐라고 생각하나요.  종이에 그림을 그리는 것 아니면 멋진 조각 작품을 만드는 것 그런데 지금의 미술은 꼭 그림이나 조각품만이 아니랍니다.  비디오 아트 행위 예술 벽의 낙서까지 그 어떤 것도 예술이고 미술일 수 있다고 해요. 그럼 오늘 신나는 동화여행 속에서 알쏭달쏭 현대미술관으로 재미있고 엉뚱한 작품을 만나러 가볼까요.  알쏭달쏭 미술관 \"나는 알쏭달쏭 미술관 관장 \\'<인물0>\\'란다 이곳은 신기하고 괴상한 작품으로 가득하지 재미있는 미술 작품들이 가득한 알쏭달쏭 미술관에 온 걸 환영합니다.\" \"이쪽에 있는 변기를 볼래? 화장실에서나 볼 수 있는 변기가 미술 작품이라면 믿겠니?\" \"네? 변기가 미술 작품이라구요?\" \"너희들 모나리자란 그림을 알고 있지? 레오나르도 다빈치가 그린 그림이야. 그런데 뒤샹이라는 화가는 모나리자의 얼굴에 수염만 그리고 전시를 했단다. 그래서 사람들은 깜짝 놀랐지.\" \"네? 유명한 작품에 낙서를 한 게 미술 작품이라구요?\" \"뒤샹은 장난꾸러기였나봐. 그럼 이거는 뭘 그린 건지 한번 맞춰볼래? 여러 색깔의 물감을 뿌리고 붓고 흘린 거란다 곳곳에 커다란 물감 얼룩도 있지\" \"폴록이라는 화가는 이게 연보라빛 안개라는구나. 그런데 미술관 관장인 내가 봐도 신나게 물감을 뿌려 놓은 것 같거든 혹시 너희들 눈에는 안개가 보이니?\" \"글쎄요? 보이는 것도 같고 아닌 것 같기도 하고..\" \"그렇게 볼록은 커다란 종류의 물감을 쏟아 부었어. 그리고 붓을 휘젓고 물감을 튀겼지. 가끔은 물감 대신 모래를 톡톡 뿌리기도 했단다. 진짜 신났겠지?\" \"물감을 가지고 장난치는 것 같아...\" \"화가 에른스트는 물건의 종이를 대고 문지르면서 작품을 만들었어. 어떤 물건이냐에 따라 무늬가 달라지지!\" \"에이 이건 나도 그릴 수 있을 것 같아.\" \"종이에 물감을 쭉 짜놓고 접었다가 펴면 양쪽에 똑같은 그림이 나타나지 이걸 \\'데칼코마니\\'라고 한단다.\" \"이 그림은 어떠냐 이것도 미술 작품이야. 리엔텐 슈타인은 만화의 한 장면에 검은 선을 그린 다음 알록달록 색칠을 했단다 진짜 만화책처럼 보이려고 촘촘히 작은 점도 찍었어.\"  \"관장님 저도 만화책으로 작품을 만들어 볼래요!\" \"그리고 리히텐슈타인은 말풍선 안에 글도 넣었단다. 누구나 알기 쉽게 재미있는 그림을 그리고 싶었던 거야 어때 만화를 보는 것처럼 쉽지?\" \"네 꼭 만화책 같아요.\" \"햄버거와 막대 아이스크림을 미술 작품이라고 전시한 미술가도 있단다. 먹고 싶다기보다는 깔고 앉고 싶지.\" \"물론 절대로 먹을 수는 없어 고무와 상자 천으로 만들어졌거든.\" \"야 이런 것도 현대미술이구나. 어 갑자기 배가 고파져.\" \"화가 올덴버*그녀는 반대로 생각하는 걸 좋아했단다. 사람이나 눈물 대신 물건이나 음식을 조각으로 만들었어. \"숟가락, 미끄럼틀, 먹다 버린 사과, 배드민턴 공 이런 재료들이 모두 미술이 되었지 재료도 이것저것 써서 작은 곳은 엄청 크게 단단한 곳은 물렁물렁하게 만들었단다.\" \"먹다 버린 사과가 멋진 작품이 된 거야.\"  \"심심해서 끄적거리는 것도 미술이 될까?\" \"화가 바스키아는 지하철과 길거리 벽에 글을 쓰고 그림을 그렸어. 아프리카 가면을 닮은 얼굴이랑 글자 화려한 색깔과 모양이 어우러져 활기찬 그림이 되었지.\" \"낙서가 예술 작품이 될 수 있다구요? 어 그럼 나도 벌써 예술간데..?\" \"스미스슨이라는 화가는 호수의 빙글빙글 달팽이 집 모양 둑을 만들었어. 이건 비행기를 타야 볼 수 있겠지.  \"저기요 저기 멋진 둑이 보여요.\" \"이 둑은 물에 잠기기도 하고 부서지거나 깎이면서 조금씩 없어진단다. 이런 것까지도 작품이라고 생각했단다. 현대 미술가들은 톡톡 튀는 생각 톡톡 튀는 방법으로 작품을 만들어요.\" \"허스트는 죽은 동물이나 알약으로 죽음을 표현했단다.\" \"그런데 이게 모두 미술이 맞는 걸까?\"  \"미술이 그림을 그리는 것만은 아닌가 봐요. 그래 맞아 현대 미술가들은 자기가 그리고 싶은 대로 그리고 만들고 싶은 대로 만들지 우리는 그냥 보이는 대로 느끼면 된단다.\" 정말 생각지도 않았던 것들이 미술 작품으로 전시되어 있었어요. 이렇게 현대미술은 표현 방법이나 주제 또 재료와 도구들이 아주 아주 다양해졌답니다. 우리 친구들도 느끼는 대로 생각하는 대로 머릿속에 그려지는 상상력을 마음껏 나타내 보세요. 바로 그게 미술이니까요. 그럼 우리는 다음에 또 다른 이야기로 다시 만나요. 안녕~'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_swapped_df['동화'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16cbef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_swapped_df.to_csv('dataset/swapped_data_0822.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234ba5a",
   "metadata": {},
   "source": [
    "# 4. Labeling\n",
    "seq2seq 모델에 적용하기 위해 데이터셋의 앞 두 문장을 input으로, 스토리 전체를 target으로 학습 데이터를 수정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eee844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset_0831_unsmile.xlsx', engine='openpyxl')\n",
    "df = df.dropna(axis=0)\n",
    "df = df.drop(index=520, axis=0)\n",
    "#df = df.drop(index=303, axis=0)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a17e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_sentences(text):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        text (str): raw text to split to sentences on end of sentences marks.\n",
    "    Returns:\n",
    "        List of sentences from text.\n",
    "    \"\"\"\n",
    "    # Split on end of sentence, but keep the punctuation marks.\n",
    "    text = text.replace('\\n', '')\n",
    "    sentences = text.split('.')\n",
    "    # If the last sentence is ''\n",
    "    if len(sentences) > 1 and len(sentences[-1]) < 3:\n",
    "        sentences.pop()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56633b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(df)):\n",
    "    text = df['동화'][i]\n",
    "    sentences = split_to_sentences(text)\n",
    "\n",
    "    label = sentences[0] + '.' + sentences[1]\n",
    "    labels.append(label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = df.assign(label = labels)\n",
    "labeled_df.rename(columns = {'동화':'target'},inplace=True)\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36267111",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.to_csv('labeld_dataset_0902.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6ca58ca60af1a323d2fd1825711943899e8fdf116af5f48df7110b796a46c0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
